{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bR52S4pkll-B"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def dropout_layer(activations, p=0.5, training=True):\n",
        "    \"\"\"\n",
        "    Применяет dropout к вектору активаций.\n",
        "\n",
        "    Параметры:\n",
        "    - activations: список чисел [a1, a2, ..., an] — выходы нейронов\n",
        "    - p: вероятность \"выключения\" нейрона (обычно 0.1–0.5)\n",
        "    - training: bool, указывает, идёт ли обучение\n",
        "\n",
        "    Возвращает:\n",
        "    - Список: модифицированные активации\n",
        "    \"\"\"\n",
        "    if not training:\n",
        "        # На инференсе — ничего не меняем\n",
        "        return activations[:]\n",
        "\n",
        "    n = len(activations)\n",
        "    mask = []\n",
        "    dropped_activations = []\n",
        "\n",
        "    # Создаём маску: 1 с вероятностью (1 - p), 0 с вероятностью p\n",
        "    for i in range(n):\n",
        "        if random.random() < (1 - p):\n",
        "            mask.append(1.0)\n",
        "        else:\n",
        "            mask.append(0.0)\n",
        "\n",
        "    # Применяем маску и масштабируем (inverted dropout)\n",
        "    scaling_factor = 1.0 / (1.0 - p)\n",
        "    for i in range(n):\n",
        "        dropped_value = activations[i] * mask[i] * scaling_factor\n",
        "        dropped_activations.append(dropped_value)\n",
        "\n",
        "    return dropped_activations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout_batch(activations_batch, p=0.5, training=True):\n",
        "    \"\"\"\n",
        "    Активации: список списков — каждый подсписок — активации одного образца\n",
        "    \"\"\"\n",
        "    if not training:\n",
        "        return [row[:] for row in activations_batch]\n",
        "\n",
        "    result = []\n",
        "    scaling_factor = 1.0 / (1.0 - p)\n",
        "    for sample in activations_batch:\n",
        "        dropped_sample = []\n",
        "        for value in sample:\n",
        "            keep = 1.0 if random.random() < (1 - p) else 0.0\n",
        "            dropped_sample.append(value * keep * scaling_factor)\n",
        "        result.append(dropped_sample)\n",
        "    return result"
      ],
      "metadata": {
        "id": "dHsllGQQngLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}