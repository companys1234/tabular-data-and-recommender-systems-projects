{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELvSUb39EEA1",
        "outputId": "6307fb9c-c47a-4a60-dcdf-1f68e9b8f030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример данных взаимодействий:\n",
            "columns: ['user_id', 'item_id', 'interaction_type', 'rating', 'timestamp']\n",
            "\n",
            "Пример метаданных объектов:\n",
            "columns: ['item_id', 'category', 'brand', 'price', 'created_at', 'title', 'description']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Предположим, у нас есть следующие датафреймы:\n",
        "# interactions - все взаимодействия пользователей с объектами\n",
        "# items - метаданные объектов\n",
        "# users - метаданные пользователей (если есть)\n",
        "\n",
        "# Примерная структура данных:\n",
        "print(\"Пример данных взаимодействий:\")\n",
        "print(\"columns: ['user_id', 'item_id', 'interaction_type', 'rating', 'timestamp']\")\n",
        "print(\"\\nПример метаданных объектов:\")\n",
        "print(\"columns: ['item_id', 'category', 'brand', 'price', 'created_at', 'title', 'description']\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_item_popularity_features(interactions_df, items_meta_df, current_date=None):\n",
        "    \"\"\"\n",
        "    Создает признаки популярности объектов.\n",
        "\n",
        "    Args:\n",
        "        interactions_df: DataFrame с колонками ['item_id', 'timestamp', 'interaction_type']\n",
        "        items_meta_df: DataFrame с метаданными объектов\n",
        "        current_date: Дата, на которую считаем признаки (для валидации/теста)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame с признаками для каждого item_id\n",
        "    \"\"\"\n",
        "    if current_date is None:\n",
        "        current_date = interactions_df['timestamp'].max()\n",
        "    else:\n",
        "        current_date = pd.to_datetime(current_date)\n",
        "\n",
        "    # Копируем датафрейм, чтобы не менять оригинал\n",
        "    interactions = interactions_df.copy()\n",
        "    interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
        "\n",
        "    # Создаем пустой датафрейм для результатов\n",
        "    item_features = pd.DataFrame()\n",
        "    item_features['item_id'] = interactions['item_id'].unique()\n",
        "\n",
        "    # Базовые даты для временных окон\n",
        "    one_day_ago = current_date - timedelta(days=1)\n",
        "    seven_days_ago = current_date - timedelta(days=7)\n",
        "    thirty_days_ago = current_date - timedelta(days=30)\n",
        "    fourteen_days_ago = current_date - timedelta(days=14)\n",
        "\n",
        "    # 1. Популярность за всё время\n",
        "    total_popularity = interactions.groupby('item_id').size().reset_index(name='item_popularity_total')\n",
        "    item_features = item_features.merge(total_popularity, on='item_id', how='left')\n",
        "    item_features['item_popularity_total'] = item_features['item_popularity_total'].fillna(0).astype(int)\n",
        "\n",
        "    # 2. Популярность за временные окна\n",
        "    # Последние 30 дней\n",
        "    recent_30d = interactions[interactions['timestamp'] >= thirty_days_ago]\n",
        "    pop_30d = recent_30d.groupby('item_id').size().reset_index(name='item_popularity_30d')\n",
        "    item_features = item_features.merge(pop_30d, on='item_id', how='left')\n",
        "    item_features['item_popularity_30d'] = item_features['item_popularity_30d'].fillna(0).astype(int)\n",
        "\n",
        "    # Последние 7 дней\n",
        "    recent_7d = interactions[interactions['timestamp'] >= seven_days_ago]\n",
        "    pop_7d = recent_7d.groupby('item_id').size().reset_index(name='item_popularity_7d')\n",
        "    item_features = item_features.merge(pop_7d, on='item_id', how='left')\n",
        "    item_features['item_popularity_7d'] = item_features['item_popularity_7d'].fillna(0).astype(int)\n",
        "\n",
        "    # Последние 1 день\n",
        "    recent_1d = interactions[interactions['timestamp'] >= one_day_ago]\n",
        "    pop_1d = recent_1d.groupby('item_id').size().reset_index(name='item_popularity_1d')\n",
        "    item_features = item_features.merge(pop_1d, on='item_id', how='left')\n",
        "    item_features['item_popularity_1d'] = item_features['item_popularity_1d'].fillna(0).astype(int)\n",
        "\n",
        "    # 3. Тренд популярности (отношение последней недели к предыдущей)\n",
        "    week1 = interactions[(interactions['timestamp'] >= seven_days_ago) &\n",
        "                        (interactions['timestamp'] < one_day_ago)]\n",
        "    week2 = interactions[(interactions['timestamp'] >= fourteen_days_ago) &\n",
        "                        (interactions['timestamp'] < seven_days_ago)]\n",
        "\n",
        "    pop_week1 = week1.groupby('item_id').size().reset_index(name='pop_week1')\n",
        "    pop_week2 = week2.groupby('item_id').size().reset_index(name='pop_week2')\n",
        "\n",
        "    # Объединяем и считаем тренд\n",
        "    trend_df = pop_week1.merge(pop_week2, on='item_id', how='outer').fillna(0.1)  # 0.1 чтобы избежать деления на 0\n",
        "    trend_df['item_popularity_trend'] = (trend_df['pop_week1'] + 1) / (trend_df['pop_week2'] + 1)\n",
        "\n",
        "    item_features = item_features.merge(trend_df[['item_id', 'item_popularity_trend']],\n",
        "                                       on='item_id', how='left')\n",
        "    item_features['item_popularity_trend'] = item_features['item_popularity_trend'].fillna(1.0)\n",
        "\n",
        "    # 4. Стандартное отклонение популярности по дням\n",
        "    # Группируем по дням для каждого объекта\n",
        "    interactions['date'] = interactions['timestamp'].dt.date\n",
        "\n",
        "    # Берем данные за последние 30 дней для стабильности\n",
        "    recent_for_std = interactions[interactions['timestamp'] >= thirty_days_ago]\n",
        "    daily_popularity = recent_for_std.groupby(['item_id', 'date']).size().reset_index(name='daily_count')\n",
        "\n",
        "    # Если у объекта мало дней с взаимодействиями, заполняем нулями\n",
        "    all_dates = pd.date_range(start=thirty_days_ago.date(), end=current_date.date(), freq='D')\n",
        "    all_items = interactions['item_id'].unique()\n",
        "\n",
        "    # Создаем полную сетку и заполняем нулями отсутствующие дни\n",
        "    idx = pd.MultiIndex.from_product([all_items, all_dates], names=['item_id', 'date'])\n",
        "    full_grid = pd.DataFrame(index=idx).reset_index()\n",
        "    full_grid['date'] = pd.to_datetime(full_grid['date'])\n",
        "\n",
        "    daily_popularity['date'] = pd.to_datetime(daily_popularity['date'])\n",
        "    full_popularity = pd.merge(full_grid, daily_popularity,\n",
        "                              on=['item_id', 'date'], how='left')\n",
        "    full_popularity['daily_count'] = full_popularity['daily_count'].fillna(0)\n",
        "\n",
        "    # Считаем стандартное отклонение\n",
        "    popularity_std = full_popularity.groupby('item_id')['daily_count'].std().reset_index(name='item_popularity_std')\n",
        "    popularity_std['item_popularity_std'] = popularity_std['item_popularity_std'].fillna(0)\n",
        "\n",
        "    item_features = item_features.merge(popularity_std, on='item_id', how='left')\n",
        "\n",
        "    # 5. Временные признаки объекта\n",
        "    if 'created_at' in items_meta_df.columns:\n",
        "        items_meta_df['created_at'] = pd.to_datetime(items_meta_df['created_at'])\n",
        "\n",
        "        # Возраст объекта в днях\n",
        "        items_meta_df['item_age_days'] = (current_date - items_meta_df['created_at']).dt.days\n",
        "\n",
        "        # Флаг нового объекта\n",
        "        items_meta_df['is_new_item'] = (items_meta_df['item_age_days'] <= 7).astype(int)\n",
        "\n",
        "        item_features = item_features.merge(\n",
        "            items_meta_df[['item_id', 'item_age_days', 'is_new_item']],\n",
        "            on='item_id', how='left'\n",
        "        )\n",
        "\n",
        "    # 6. Days since last interaction\n",
        "    last_interaction = interactions.groupby('item_id')['timestamp'].max().reset_index()\n",
        "    last_interaction['days_since_last_interaction'] = (\n",
        "        current_date - last_interaction['timestamp']\n",
        "    ).dt.days\n",
        "\n",
        "    item_features = item_features.merge(\n",
        "        last_interaction[['item_id', 'days_since_last_interaction']],\n",
        "        on='item_id', how='left'\n",
        "    )\n",
        "    item_features['days_since_last_interaction'] = item_features['days_since_last_interaction'].fillna(999)\n",
        "\n",
        "    return item_features"
      ],
      "metadata": {
        "id": "rLi3ODiEFme5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_item_interaction_stats(interactions_df, items_meta_df=None):\n",
        "    \"\"\"\n",
        "    Создает статистики по взаимодействиям с объектами.\n",
        "\n",
        "    Args:\n",
        "        interactions_df: DataFrame с колонками ['item_id', 'interaction_type', 'rating']\n",
        "                         interaction_type может быть: 'click', 'purchase', 'view', 'add_to_cart', etc.\n",
        "                         rating: числовой рейтинг (1-5)\n",
        "    \"\"\"\n",
        "    interactions = interactions_df.copy()\n",
        "    item_stats = pd.DataFrame()\n",
        "    item_stats['item_id'] = interactions['item_id'].unique()\n",
        "\n",
        "    # 1. Средний рейтинг\n",
        "    if 'rating' in interactions.columns:\n",
        "        avg_rating = interactions.groupby('item_id')['rating'].mean().reset_index(name='item_avg_rating')\n",
        "        rating_count = interactions.groupby('item_id')['rating'].count().reset_index(name='item_rating_count')\n",
        "\n",
        "        item_stats = item_stats.merge(avg_rating, on='item_id', how='left')\n",
        "        item_stats = item_stats.merge(rating_count, on='item_id', how='left')\n",
        "\n",
        "        # Распределение оценок\n",
        "        for rating_val in [1, 2, 3, 4, 5]:\n",
        "            rating_mask = interactions['rating'] == rating_val\n",
        "            rating_counts = interactions[rating_mask].groupby('item_id').size().reset_index(name=f'item_rating_{rating_val}_stars')\n",
        "            item_stats = item_stats.merge(rating_counts, on='item_id', how='left')\n",
        "            item_stats[f'item_rating_{rating_val}_stars'] = item_stats[f'item_rating_{rating_val}_stars'].fillna(0)\n",
        "\n",
        "        # Процент 5-звездочных оценок\n",
        "        item_stats['item_pct_5_stars'] = np.where(\n",
        "            item_stats['item_rating_count'] > 0,\n",
        "            item_stats['item_rating_5_stars'] / item_stats['item_rating_count'],\n",
        "            0\n",
        "        )\n",
        "\n",
        "    # 2. CTR и конверсии (если есть данные о показах)\n",
        "    if 'interaction_type' in interactions.columns:\n",
        "        # Считаем разные типы взаимодействий\n",
        "        interaction_counts = interactions.groupby(['item_id', 'interaction_type']).size().unstack(fill_value=0)\n",
        "\n",
        "        # CTR (клики / показы)\n",
        "        if 'click' in interaction_counts.columns and 'view' in interaction_counts.columns:\n",
        "            item_stats['item_ctr'] = interaction_counts['click'] / (interaction_counts['view'] + 1)\n",
        "\n",
        "        # Конверсия покупок\n",
        "        if 'purchase' in interaction_counts.columns and 'view' in interaction_counts.columns:\n",
        "            item_stats['item_purchase_conversion'] = interaction_counts['purchase'] / (interaction_counts['view'] + 1)\n",
        "\n",
        "        # Общий success ratio (например, положительные взаимодействия / все)\n",
        "        if 'purchase' in interaction_counts.columns or 'click' in interaction_counts.columns:\n",
        "            positive_cols = [col for col in ['purchase', 'click', 'add_to_cart'] if col in interaction_counts.columns]\n",
        "            if positive_cols:\n",
        "                positive_interactions = interaction_counts[positive_cols].sum(axis=1)\n",
        "                total_interactions = interaction_counts.sum(axis=1)\n",
        "                item_stats['item_success_ratio'] = positive_interactions / (total_interactions + 1)\n",
        "\n",
        "    # 3. Более сложные статистики по времени\n",
        "    if 'timestamp' in interactions.columns:\n",
        "        interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
        "\n",
        "        # Скорость набора популярности\n",
        "        first_interaction = interactions.groupby('item_id')['timestamp'].min().reset_index(name='first_interaction_time')\n",
        "        last_interaction = interactions.groupby('item_id')['timestamp'].max().reset_index(name='last_interaction_time')\n",
        "\n",
        "        time_info = first_interaction.merge(last_interaction, on='item_id')\n",
        "        time_info['item_lifetime_days'] = (time_info['last_interaction_time'] - time_info['first_interaction_time']).dt.days + 1\n",
        "\n",
        "        item_stats = item_stats.merge(time_info[['item_id', 'item_lifetime_days']], on='item_id', how='left')\n",
        "\n",
        "        # Популярность в день (интенсивность)\n",
        "        \"\"\"        item_stats = item_stats.merge(\n",
        "                    total_popularity.rename(columns={'item_popularity_total': 'total_interactions'}),\n",
        "                    on='item_id', how='left'\n",
        "                )\n",
        "                item_stats['item_popularity_per_day'] = np.where(\n",
        "                    item_stats['item_lifetime_days'] > 0,\n",
        "                    item_stats['total_interactions'] / item_stats['item_lifetime_days'],\n",
        "                    0\n",
        "                )\n",
        "        \"\"\"\n",
        "    return item_stats"
      ],
      "metadata": {
        "id": "6VokWCGJF5x7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_item_metadata_features(items_meta_df):\n",
        "    \"\"\"\n",
        "    Создает признаки из метаданных объектов.\n",
        "    \"\"\"\n",
        "    items_meta = items_meta_df.copy()\n",
        "    features = pd.DataFrame()\n",
        "    features['item_id'] = items_meta['item_id']\n",
        "\n",
        "    # 1. Категориальные признаки (просто берем как есть)\n",
        "    categorical_cols = ['category', 'brand', 'author', 'genre', 'color',\n",
        "                       'subcategory', 'manufacturer', 'country']\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        if col in items_meta.columns:\n",
        "            features[f'item_{col}'] = items_meta[col].fillna('unknown')\n",
        "\n",
        "    # 2. Иерархические категории (разбиваем путь)\n",
        "    if 'category_path' in items_meta.columns:\n",
        "        # Пример: \"Электроника -> Смартфоны -> Apple\"\n",
        "        paths = items_meta['category_path'].str.split(' -> ', expand=True)\n",
        "\n",
        "        for i in range(min(3, paths.shape[1])):  # Берем максимум 3 уровня\n",
        "            features[f'item_category_level_{i+1}'] = paths[i].fillna('unknown')\n",
        "\n",
        "    # 3. Текстовые признаки\n",
        "    if 'title' in items_meta.columns:\n",
        "        features['item_title_length'] = items_meta['title'].fillna('').apply(len)\n",
        "        features['item_title_word_count'] = items_meta['title'].fillna('').apply(lambda x: len(str(x).split()))\n",
        "\n",
        "        # Ключевые слова в названии\n",
        "        keywords = ['sale', 'new', 'limited', 'exclusive', 'bestseller', 'discount']\n",
        "        for keyword in keywords:\n",
        "            features[f'item_title_has_{keyword}'] = items_meta['title'].fillna('').str.lower().str.contains(keyword).astype(int)\n",
        "\n",
        "    if 'description' in items_meta.columns:\n",
        "        features['item_description_length'] = items_meta['description'].fillna('').apply(len)\n",
        "        features['item_has_description'] = (items_meta['description'].notna() &\n",
        "                                           (items_meta['description'].str.strip() != '')).astype(int)\n",
        "\n",
        "    # 4. Числовые признаки\n",
        "    numeric_cols = ['price', 'weight', 'size', 'length', 'width', 'height', 'volume']\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        if col in items_meta.columns:\n",
        "            features[f'item_{col}'] = pd.to_numeric(items_meta[col], errors='coerce')\n",
        "\n",
        "            # Логарифмирование для skewed распределений\n",
        "            if features[f'item_{col}'].min() > 0:\n",
        "                features[f'item_{col}_log'] = np.log1p(features[f'item_{col}'])\n",
        "\n",
        "    # 5. Ценовые признаки\n",
        "    if 'price' in items_meta.columns:\n",
        "        # Признаки скидки\n",
        "        if 'original_price' in items_meta.columns:\n",
        "            features['item_discount_amount'] = items_meta['original_price'] - items_meta['price']\n",
        "            features['item_discount_percentage'] = np.where(\n",
        "                items_meta['original_price'] > 0,\n",
        "                (items_meta['original_price'] - items_meta['price']) / items_meta['original_price'] * 100,\n",
        "                0\n",
        "            )\n",
        "            features['item_is_discounted'] = (features['item_discount_percentage'] > 0).astype(int)\n",
        "        else:\n",
        "            # Если нет оригинальной цены, можно использовать медианную по категории\n",
        "            if 'category' in items_meta.columns:\n",
        "                median_price_by_category = items_meta.groupby('category')['price'].transform('median')\n",
        "                features['item_price_vs_category_median'] = items_meta['price'] / (median_price_by_category + 1)\n",
        "\n",
        "    # 6. Цена за единицу (если есть вес или объем)\n",
        "    if 'price' in items_meta.columns and 'weight' in items_meta.columns:\n",
        "        features['item_price_per_kg'] = np.where(\n",
        "            items_meta['weight'] > 0,\n",
        "            items_meta['price'] / items_meta['weight'],\n",
        "            np.nan\n",
        "        )\n",
        "\n",
        "    if 'price' in items_meta.columns and 'volume' in items_meta.columns:\n",
        "        features['item_price_per_liter'] = np.where(\n",
        "            items_meta['volume'] > 0,\n",
        "            items_meta['price'] / items_meta['volume'],\n",
        "            np.nan\n",
        "        )\n",
        "\n",
        "    # 7. Бинарные признаки из категориальных\n",
        "    if 'brand' in items_meta.columns:\n",
        "        # Флаг для топ-брендов\n",
        "        top_brands = items_meta['brand'].value_counts().head(10).index\n",
        "        features['item_is_top_brand'] = items_meta['brand'].isin(top_brands).astype(int)\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "EeuF8-XQGI5J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "def create_text_features(items_meta_df, text_column='title', n_components=20):\n",
        "    \"\"\"\n",
        "    Создает TF-IDF эмбеддинги для текстовых полей.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame с эмбеддингами и оригинальный vectorizer для трансформации новых данных\n",
        "    \"\"\"\n",
        "    if text_column not in items_meta_df.columns:\n",
        "        return pd.DataFrame({'item_id': items_meta_df['item_id']}), None\n",
        "\n",
        "    # Подготовка текста\n",
        "    texts = items_meta_df[text_column].fillna('').astype(str).tolist()\n",
        "\n",
        "    # TF-IDF векторзация\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=1000,\n",
        "        min_df=2,\n",
        "        max_df=0.8,\n",
        "        stop_words='english',  # или 'russian'\n",
        "        ngram_range=(1, 2)\n",
        "    )\n",
        "\n",
        "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "    # Уменьшение размерности\n",
        "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "    embeddings = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "    # Создаем DataFrame с эмбеддингами\n",
        "    embedding_cols = [f'item_{text_column}_embed_{i}' for i in range(n_components)]\n",
        "    embeddings_df = pd.DataFrame(embeddings, columns=embedding_cols)\n",
        "    embeddings_df['item_id'] = items_meta_df['item_id'].values\n",
        "\n",
        "    return embeddings_df, vectorizer"
      ],
      "metadata": {
        "id": "No1MoEtRGKmI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_all_item_features(interactions_df, items_meta_df, current_date=None):\n",
        "    \"\"\"\n",
        "    Создает все признаки объектов в одном датафрейме.\n",
        "\n",
        "    Args:\n",
        "        interactions_df: DataFrame взаимодействий\n",
        "        items_meta_df: DataFrame метаданных\n",
        "        current_date: Дата для валидации/теста\n",
        "\n",
        "    Returns:\n",
        "        DataFrame со всеми признаками\n",
        "    \"\"\"\n",
        "    print(\"Создание признаков популярности...\")\n",
        "    popularity_features = create_item_popularity_features(\n",
        "        interactions_df, items_meta_df, current_date\n",
        "    )\n",
        "\n",
        "    print(\"Создание статистик взаимодействий...\")\n",
        "    interaction_features = create_item_interaction_stats(interactions_df)\n",
        "\n",
        "    print(\"Создание признаков из метаданных...\")\n",
        "    metadata_features = create_item_metadata_features(items_meta_df)\n",
        "\n",
        "    # Объединяем все признаки\n",
        "    print(\"Объединение всех признаков...\")\n",
        "    all_features = popularity_features.copy()\n",
        "\n",
        "    # Последовательно объединяем\n",
        "    for features_df in [interaction_features, metadata_features]:\n",
        "        all_features = all_features.merge(\n",
        "            features_df,\n",
        "            on='item_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "    # Дополнительно: нормализуем числовые признаки\n",
        "    print(\"Нормализация числовых признаков...\")\n",
        "    numeric_cols = all_features.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "    # Исключаем ID и бинарные признаки\n",
        "    exclude_cols = ['item_id', 'is_new_item', 'item_is_discounted', 'item_is_top_brand']\n",
        "    numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "    # Min-Max нормализация\n",
        "    for col in numeric_cols:\n",
        "        if all_features[col].nunique() > 1:  # Не нормализуем константы\n",
        "            min_val = all_features[col].min()\n",
        "            max_val = all_features[col].max()\n",
        "            if max_val > min_val:  # Избегаем деления на 0\n",
        "                all_features[f'{col}_norm'] = (all_features[col] - min_val) / (max_val - min_val)\n",
        "\n",
        "    print(f\"Создано признаков: {all_features.shape[1] - 1}\")  # минус item_id\n",
        "    print(f\"Количество объектов: {all_features.shape[0]}\")\n",
        "\n",
        "    return all_features"
      ],
      "metadata": {
        "id": "51r7tg-jGUFi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример синтетических данных\n",
        "np.random.seed(42)\n",
        "\n",
        "# Создаем данные взаимодействий\n",
        "n_interactions = 10000\n",
        "n_items = 1000\n",
        "n_users = 500\n",
        "\n",
        "interactions_data = {\n",
        "    'user_id': np.random.randint(1, n_users+1, n_interactions),\n",
        "    'item_id': np.random.randint(1, n_items+1, n_interactions),\n",
        "    'interaction_type': np.random.choice(['click', 'view', 'purchase', 'add_to_cart'],\n",
        "                                        n_interactions, p=[0.5, 0.3, 0.15, 0.05]),\n",
        "    'rating': np.random.choice([1, 2, 3, 4, 5, np.nan], n_interactions, p=[0.05, 0.1, 0.15, 0.3, 0.3, 0.1]),\n",
        "    'timestamp': pd.date_range(start='2024-01-01', periods=n_interactions, freq='H')\n",
        "}\n",
        "\n",
        "interactions_df = pd.DataFrame(interactions_data)\n",
        "\n",
        "# Создаем метаданные объектов\n",
        "items_data = {\n",
        "    'item_id': range(1, n_items+1),\n",
        "    'category': np.random.choice(['Electronics', 'Books', 'Clothing', 'Home', 'Sports'], n_items),\n",
        "    'brand': np.random.choice(['Brand_A', 'Brand_B', 'Brand_C', 'Brand_D', 'Brand_E', 'Unknown'], n_items),\n",
        "    'price': np.random.exponential(100, n_items).round(2),\n",
        "    'created_at': pd.date_range(start='2023-06-01', periods=n_items, freq='D'),\n",
        "    'title': [f'Product_{i}' for i in range(1, n_items+1)],\n",
        "    'description': [f'Description for product {i}' for i in range(1, n_items+1)]\n",
        "}\n",
        "\n",
        "items_meta_df = pd.DataFrame(items_data)\n",
        "\n",
        "# Создаем все признаки\n",
        "print(\"=\" * 50)\n",
        "print(\"СОЗДАНИЕ ПРИЗНАКОВ ДЛЯ ОБЪЕКТОВ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "item_features_df = create_all_item_features(\n",
        "    interactions_df=interactions_df,\n",
        "    items_meta_df=items_meta_df,\n",
        "    current_date='2024-02-01'\n",
        ")\n",
        "\n",
        "# Посмотрим на результат\n",
        "print(\"\\nПервые 5 строк финального датафрейма:\")\n",
        "print(item_features_df.head())\n",
        "\n",
        "print(\"\\nКолонки в финальном датафрейме:\")\n",
        "print(item_features_df.columns.tolist())\n",
        "\n",
        "print(\"\\nБазовая статистика по признакам:\")\n",
        "print(item_features_df.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4spAmhtHXfa",
        "outputId": "1a2cb646-66f6-47f8-da56-4b6bafde1a26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "СОЗДАНИЕ ПРИЗНАКОВ ДЛЯ ОБЪЕКТОВ\n",
            "==================================================\n",
            "Создание признаков популярности...\n",
            "Создание статистик взаимодействий...\n",
            "Создание признаков из метаданных...\n",
            "Объединение всех признаков...\n",
            "Нормализация числовых признаков...\n",
            "Создано признаков: 62\n",
            "Количество объектов: 1000\n",
            "\n",
            "Первые 5 строк финального датафрейма:\n",
            "   item_id  item_popularity_total  item_popularity_30d  item_popularity_7d  \\\n",
            "0      182                      8                    7                   6   \n",
            "1       13                     14                   13                  13   \n",
            "2      339                      8                    7                   7   \n",
            "3      797                      7                    6                   6   \n",
            "4      259                     14                   13                  13   \n",
            "\n",
            "   item_popularity_1d  item_popularity_trend  item_popularity_std  \\\n",
            "0                   6               1.000000             0.179605   \n",
            "1                  12               1.818182             0.179605   \n",
            "2                   7               1.000000             0.000000   \n",
            "3                   6               1.000000             0.000000   \n",
            "4                  11               2.727273             0.249731   \n",
            "\n",
            "   item_age_days  is_new_item  days_since_last_interaction  ...  \\\n",
            "0             64            0                         -346  ...   \n",
            "1            233            0                         -341  ...   \n",
            "2            -93            1                         -230  ...   \n",
            "3           -551            1                         -385  ...   \n",
            "4            -13            1                         -337  ...   \n",
            "\n",
            "   item_pct_5_stars_norm  item_ctr_norm  item_purchase_conversion_norm  \\\n",
            "0               0.428571            NaN                            NaN   \n",
            "1               0.285714       0.044444                       0.085714   \n",
            "2               0.666667       0.055556                       0.035714   \n",
            "3               0.400000       0.277778                       0.214286   \n",
            "4               0.357143       0.138889                       0.035714   \n",
            "\n",
            "   item_success_ratio_norm  item_lifetime_days_norm  item_title_length_norm  \\\n",
            "0                      NaN                 0.903941                0.666667   \n",
            "1                 0.538462                 0.891626                0.333333   \n",
            "2                 0.598291                 0.618227                0.666667   \n",
            "3                 0.897436                 1.000000                0.666667   \n",
            "4                 0.646154                 0.881773                0.666667   \n",
            "\n",
            "   item_description_length_norm  item_price_norm  item_price_log_norm  \\\n",
            "0                      0.666667         0.486515             0.890345   \n",
            "1                      0.333333         0.076966             0.611473   \n",
            "2                      0.666667         0.077361             0.612238   \n",
            "3                      0.666667         0.033772             0.489343   \n",
            "4                      0.666667         0.476121             0.887061   \n",
            "\n",
            "   item_price_vs_category_median_norm  \n",
            "0                            0.428257  \n",
            "1                            0.069503  \n",
            "2                            0.076647  \n",
            "3                            0.039652  \n",
            "4                            0.471723  \n",
            "\n",
            "[5 rows x 63 columns]\n",
            "\n",
            "Колонки в финальном датафрейме:\n",
            "['item_id', 'item_popularity_total', 'item_popularity_30d', 'item_popularity_7d', 'item_popularity_1d', 'item_popularity_trend', 'item_popularity_std', 'item_age_days', 'is_new_item', 'days_since_last_interaction', 'item_avg_rating', 'item_rating_count', 'item_rating_1_stars', 'item_rating_2_stars', 'item_rating_3_stars', 'item_rating_4_stars', 'item_rating_5_stars', 'item_pct_5_stars', 'item_ctr', 'item_purchase_conversion', 'item_success_ratio', 'item_lifetime_days', 'item_category', 'item_brand', 'item_title_length', 'item_title_word_count', 'item_title_has_sale', 'item_title_has_new', 'item_title_has_limited', 'item_title_has_exclusive', 'item_title_has_bestseller', 'item_title_has_discount', 'item_description_length', 'item_has_description', 'item_price', 'item_price_log', 'item_price_vs_category_median', 'item_is_top_brand', 'item_popularity_total_norm', 'item_popularity_30d_norm', 'item_popularity_7d_norm', 'item_popularity_1d_norm', 'item_popularity_trend_norm', 'item_popularity_std_norm', 'item_age_days_norm', 'days_since_last_interaction_norm', 'item_avg_rating_norm', 'item_rating_count_norm', 'item_rating_1_stars_norm', 'item_rating_2_stars_norm', 'item_rating_3_stars_norm', 'item_rating_4_stars_norm', 'item_rating_5_stars_norm', 'item_pct_5_stars_norm', 'item_ctr_norm', 'item_purchase_conversion_norm', 'item_success_ratio_norm', 'item_lifetime_days_norm', 'item_title_length_norm', 'item_description_length_norm', 'item_price_norm', 'item_price_log_norm', 'item_price_vs_category_median_norm']\n",
            "\n",
            "Базовая статистика по признакам:\n",
            "           item_id  item_popularity_total  item_popularity_30d  \\\n",
            "count  1000.000000            1000.000000          1000.000000   \n",
            "mean    500.500000              10.000000             9.976000   \n",
            "std     288.819436               3.192835             3.187096   \n",
            "min       1.000000               2.000000             2.000000   \n",
            "25%     250.750000               8.000000             8.000000   \n",
            "50%     500.500000              10.000000            10.000000   \n",
            "75%     750.250000              12.000000            12.000000   \n",
            "max    1000.000000              24.000000            24.000000   \n",
            "\n",
            "       item_popularity_7d  item_popularity_1d  item_popularity_trend  \\\n",
            "count         1000.000000         1000.000000            1000.000000   \n",
            "mean             9.424000            9.280000               1.037867   \n",
            "std              3.101265            3.063492               0.349608   \n",
            "min              2.000000            2.000000               0.366667   \n",
            "25%              7.000000            7.000000               1.000000   \n",
            "50%              9.000000            9.000000               1.000000   \n",
            "75%             11.000000           11.000000               1.000000   \n",
            "max             23.000000           23.000000               2.727273   \n",
            "\n",
            "       item_popularity_std  item_age_days  is_new_item  \\\n",
            "count          1000.000000    1000.000000  1000.000000   \n",
            "mean              0.110222    -254.500000     0.762000   \n",
            "std               0.109055     288.819436     0.426072   \n",
            "min               0.000000    -754.000000     0.000000   \n",
            "25%               0.000000    -504.250000     1.000000   \n",
            "50%               0.179605    -254.500000     1.000000   \n",
            "75%               0.179605      -4.750000     1.000000   \n",
            "max               0.522607     245.000000     1.000000   \n",
            "\n",
            "       days_since_last_interaction  ...  item_pct_5_stars_norm  item_ctr_norm  \\\n",
            "count                  1000.000000  ...            1000.000000     999.000000   \n",
            "mean                   -345.655000  ...               0.339141       0.168785   \n",
            "std                      40.637906  ...               0.168694       0.126552   \n",
            "min                    -386.000000  ...               0.000000       0.000000   \n",
            "25%                    -374.000000  ...               0.222222       0.088889   \n",
            "50%                    -358.000000  ...               0.333333       0.138889   \n",
            "75%                    -330.750000  ...               0.444444       0.222222   \n",
            "max                     -83.000000  ...               1.000000       1.000000   \n",
            "\n",
            "       item_purchase_conversion_norm  item_success_ratio_norm  \\\n",
            "count                     999.000000               999.000000   \n",
            "mean                        0.066421                 0.673978   \n",
            "std                         0.076521                 0.150762   \n",
            "min                         0.000000                 0.000000   \n",
            "25%                         0.023810                 0.583647   \n",
            "50%                         0.047619                 0.685315   \n",
            "75%                         0.095238                 0.783217   \n",
            "max                         1.000000                 1.000000   \n",
            "\n",
            "       item_lifetime_days_norm  item_title_length_norm  \\\n",
            "count              1000.000000             1000.000000   \n",
            "mean                  0.801581                0.631000   \n",
            "std                   0.141892                0.113366   \n",
            "min                   0.000000                0.000000   \n",
            "25%                   0.738916                0.666667   \n",
            "50%                   0.832512                0.666667   \n",
            "75%                   0.903941                0.666667   \n",
            "max                   1.000000                1.000000   \n",
            "\n",
            "       item_description_length_norm  item_price_norm  item_price_log_norm  \\\n",
            "count                   1000.000000      1000.000000          1000.000000   \n",
            "mean                       0.631000         0.136877             0.614384   \n",
            "std                        0.113366         0.134461             0.186466   \n",
            "min                        0.000000         0.000000             0.000000   \n",
            "25%                        0.666667         0.041458             0.519468   \n",
            "50%                        0.666667         0.096141             0.644847   \n",
            "75%                        0.666667         0.185677             0.744153   \n",
            "max                        1.000000         1.000000             1.000000   \n",
            "\n",
            "       item_price_vs_category_median_norm  \n",
            "count                         1000.000000  \n",
            "mean                             0.134116  \n",
            "std                              0.132813  \n",
            "min                              0.000000  \n",
            "25%                              0.039862  \n",
            "50%                              0.093031  \n",
            "75%                              0.181812  \n",
            "max                              1.000000  \n",
            "\n",
            "[8 rows x 61 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_activity_features(interactions_df, users_meta_df=None, current_date=None):\n",
        "    \"\"\"\n",
        "    Создает признаки активности пользователей.\n",
        "\n",
        "    Args:\n",
        "        interactions_df: DataFrame с колонками ['user_id', 'timestamp', 'interaction_type']\n",
        "        users_meta_df: DataFrame с метаданными пользователей (опционально)\n",
        "        current_date: Дата для расчета временных окон\n",
        "\n",
        "    Returns:\n",
        "        DataFrame с признаками пользователей\n",
        "    \"\"\"\n",
        "    if current_date is None:\n",
        "        current_date = interactions_df['timestamp'].max()\n",
        "    else:\n",
        "        current_date = pd.to_datetime(current_date)\n",
        "\n",
        "    interactions = interactions_df.copy()\n",
        "    interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
        "\n",
        "    # Создаем базовый DataFrame\n",
        "    user_features = pd.DataFrame()\n",
        "    user_features['user_id'] = interactions['user_id'].unique()\n",
        "\n",
        "    # 1. Общая активность\n",
        "    user_activity = interactions.groupby('user_id').size().reset_index(name='user_activity_count')\n",
        "    user_features = user_features.merge(user_activity, on='user_id', how='left')\n",
        "    user_features['user_activity_count'] = user_features['user_activity_count'].fillna(0).astype(int)\n",
        "\n",
        "    # 2. Активность по временным окнам\n",
        "    one_day_ago = current_date - timedelta(days=1)\n",
        "    seven_days_ago = current_date - timedelta(days=7)\n",
        "    thirty_days_ago = current_date - timedelta(days=30)\n",
        "\n",
        "    # Последние 30 дней\n",
        "    recent_30d = interactions[interactions['timestamp'] >= thirty_days_ago]\n",
        "    activity_30d = recent_30d.groupby('user_id').size().reset_index(name='user_activity_30d')\n",
        "    user_features = user_features.merge(activity_30d, on='user_id', how='left')\n",
        "    user_features['user_activity_30d'] = user_features['user_activity_30d'].fillna(0).astype(int)\n",
        "\n",
        "    # Последние 7 дней\n",
        "    recent_7d = interactions[interactions['timestamp'] >= seven_days_ago]\n",
        "    activity_7d = recent_7d.groupby('user_id').size().reset_index(name='user_activity_7d')\n",
        "    user_features = user_features.merge(activity_7d, on='user_id', how='left')\n",
        "    user_features['user_activity_7d'] = user_features['user_activity_7d'].fillna(0).astype(int)\n",
        "\n",
        "    # Последние 1 день\n",
        "    recent_1d = interactions[interactions['timestamp'] >= one_day_ago]\n",
        "    activity_1d = recent_1d.groupby('user_id').size().reset_index(name='user_activity_1d')\n",
        "    user_features = user_features.merge(activity_1d, on='user_id', how='left')\n",
        "    user_features['user_activity_1d'] = user_features['user_activity_1d'].fillna(0).astype(int)\n",
        "\n",
        "    # 3. Частота активности (интервалы между действиями)\n",
        "    # Даты первого и последнего взаимодействия\n",
        "    user_time_stats = interactions.groupby('user_id')['timestamp'].agg(['min', 'max']).reset_index()\n",
        "    user_time_stats.columns = ['user_id', 'first_interaction', 'last_interaction']\n",
        "\n",
        "    user_time_stats['user_age_in_system_days'] = (current_date - user_time_stats['first_interaction']).dt.days + 1\n",
        "    user_time_stats['user_recency_days'] = (current_date - user_time_stats['last_interaction']).dt.days\n",
        "\n",
        "    user_features = user_features.merge(\n",
        "        user_time_stats[['user_id', 'user_age_in_system_days', 'user_recency_days']],\n",
        "        on='user_id', how='left'\n",
        "    )\n",
        "\n",
        "    # Частота активности\n",
        "    user_features['user_activity_frequency'] = np.where(\n",
        "        user_features['user_age_in_system_days'] > 0,\n",
        "        user_features['user_activity_count'] / user_features['user_age_in_system_days'],\n",
        "        0\n",
        "    )\n",
        "\n",
        "    # 4. Сессионные признаки (если есть session_id)\n",
        "    if 'session_id' in interactions.columns:\n",
        "        session_stats = interactions.groupby(['user_id', 'session_id']).size().reset_index(name='session_length')\n",
        "        user_session_stats = session_stats.groupby('user_id').agg({\n",
        "            'session_id': 'count',\n",
        "            'session_length': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        user_session_stats.columns = ['user_id', 'user_session_count', 'avg_session_length']\n",
        "\n",
        "        user_features = user_features.merge(user_session_stats, on='user_id', how='left')\n",
        "        user_features['user_session_count'] = user_features['user_session_count'].fillna(0).astype(int)\n",
        "        user_features['avg_session_length'] = user_features['avg_session_length'].fillna(0)\n",
        "    else:\n",
        "        # Приближенный расчет сессий по времени\n",
        "        interactions_sorted = interactions.sort_values(['user_id', 'timestamp'])\n",
        "        interactions_sorted['time_diff'] = interactions_sorted.groupby('user_id')['timestamp'].diff()\n",
        "\n",
        "        # Сессия заканчивается, если перерыв больше 30 минут\n",
        "        interactions_sorted['new_session'] = (interactions_sorted['time_diff'] > timedelta(minutes=30)) | \\\n",
        "                                            (interactions_sorted['time_diff'].isna())\n",
        "        interactions_sorted['session_id'] = interactions_sorted.groupby('user_id')['new_session'].cumsum()\n",
        "\n",
        "        session_stats = interactions_sorted.groupby(['user_id', 'session_id']).size().reset_index(name='session_length')\n",
        "        user_session_stats = session_stats.groupby('user_id').agg({\n",
        "            'session_id': 'count',\n",
        "            'session_length': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        user_session_stats.columns = ['user_id', 'user_session_count', 'avg_session_length']\n",
        "\n",
        "        user_features = user_features.merge(user_session_stats, on='user_id', how='left')\n",
        "        user_features['user_session_count'] = user_features['user_session_count'].fillna(0).astype(int)\n",
        "        user_features['avg_session_length'] = user_features['avg_session_length'].fillna(0)\n",
        "\n",
        "    return user_features"
      ],
      "metadata": {
        "id": "6XDxgtQ4HnMs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_behavioral_features(interactions_df, items_meta_df):\n",
        "    \"\"\"\n",
        "    Создает поведенческие признаки пользователей.\n",
        "\n",
        "    Args:\n",
        "        interactions_df: DataFrame с колонками ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "        items_meta_df: DataFrame с метаданными объектов\n",
        "    \"\"\"\n",
        "    interactions = interactions_df.copy()\n",
        "    items_meta = items_meta_df.copy()\n",
        "\n",
        "    # Объединяем взаимодействия с метаданными объектов\n",
        "    interactions_with_meta = interactions.merge(\n",
        "        items_meta[['item_id', 'category', 'price']],\n",
        "        on='item_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    user_features = pd.DataFrame()\n",
        "    user_features['user_id'] = interactions['user_id'].unique()\n",
        "\n",
        "    # 1. Средний рейтинг пользователя\n",
        "    if 'rating' in interactions.columns:\n",
        "        user_avg_rating = interactions[interactions['rating'].notna()].groupby('user_id')['rating'].mean().reset_index(name='user_avg_rating')\n",
        "        user_features = user_features.merge(user_avg_rating, on='user_id', how='left')\n",
        "        user_features['user_avg_rating'] = user_features['user_avg_rating'].fillna(0)\n",
        "\n",
        "    # 2. Предпочитаемая категория\n",
        "    if 'category' in interactions_with_meta.columns:\n",
        "        # Самая частая категория\n",
        "        user_category_counts = interactions_with_meta.groupby(['user_id', 'category']).size().reset_index(name='category_count')\n",
        "        user_preferred_category = user_category_counts.loc[\n",
        "            user_category_counts.groupby('user_id')['category_count'].idxmax()\n",
        "        ][['user_id', 'category']].rename(columns={'category': 'user_preferred_category'})\n",
        "\n",
        "        user_features = user_features.merge(user_preferred_category, on='user_id', how='left')\n",
        "\n",
        "        # Диверсификация (энтропия категорий)\n",
        "        user_category_distribution = user_category_counts.pivot_table(\n",
        "            index='user_id',\n",
        "            columns='category',\n",
        "            values='category_count',\n",
        "            fill_value=0\n",
        "        )\n",
        "\n",
        "        # Нормализуем распределение\n",
        "        user_category_distribution_norm = user_category_distribution.div(\n",
        "            user_category_distribution.sum(axis=1), axis=0\n",
        "        )\n",
        "\n",
        "        # Считаем энтропию\n",
        "        user_entropy = pd.Series(\n",
        "            entropy(user_category_distribution_norm.values.T, base=2),\n",
        "            index=user_category_distribution_norm.index\n",
        "        ).reset_index(name='user_diversity')\n",
        "\n",
        "        user_features = user_features.merge(user_entropy, on='user_id', how='left')\n",
        "        user_features['user_diversity'] = user_features['user_diversity'].fillna(0)\n",
        "\n",
        "    # 3. Предпочитаемый ценовой сегмент\n",
        "    if 'price' in interactions_with_meta.columns:\n",
        "        user_price_stats = interactions_with_meta[interactions_with_meta['price'].notna()].groupby('user_id')['price'].agg([\n",
        "            'median', 'mean', 'std', 'min', 'max'\n",
        "        ]).reset_index()\n",
        "\n",
        "        user_price_stats.columns = ['user_id', 'user_preferred_price_median',\n",
        "                                   'user_avg_price', 'user_price_std',\n",
        "                                   'user_min_price', 'user_max_price']\n",
        "\n",
        "        user_features = user_features.merge(user_price_stats, on='user_id', how='left')\n",
        "\n",
        "        # Размах цен (широта интересов)\n",
        "        user_features['user_price_range'] = user_features['user_max_price'] - user_features['user_min_price']\n",
        "        user_features['user_price_variability'] = user_features['user_price_std'] / (user_features['user_avg_price'] + 1)\n",
        "\n",
        "    # 4. Предпочитаемые бренды (если есть в метаданных)\n",
        "    if 'brand' in items_meta.columns:\n",
        "        interactions_with_brand = interactions.merge(\n",
        "            items_meta[['item_id', 'brand']],\n",
        "            on='item_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        user_brand_counts = interactions_with_brand.groupby(['user_id', 'brand']).size().reset_index(name='brand_count')\n",
        "        user_preferred_brand = user_brand_counts.loc[\n",
        "            user_brand_counts.groupby('user_id')['brand_count'].idxmax()\n",
        "        ][['user_id', 'brand']].rename(columns={'brand': 'user_preferred_brand'})\n",
        "\n",
        "        user_features = user_features.merge(user_preferred_brand, on='user_id', how='left')\n",
        "\n",
        "    # 5. Количество уникальных категорий/брендов\n",
        "    if 'category' in interactions_with_meta.columns:\n",
        "        user_unique_categories = interactions_with_meta.groupby('user_id')['category'].nunique().reset_index(name='user_unique_categories_count')\n",
        "        user_features = user_features.merge(user_unique_categories, on='user_id', how='left')\n",
        "\n",
        "    return user_features"
      ],
      "metadata": {
        "id": "nckHPXa0JqHp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_temporal_patterns(interactions_df):\n",
        "    \"\"\"\n",
        "    Создает временные паттерны пользователей.\n",
        "    \"\"\"\n",
        "    interactions = interactions_df.copy()\n",
        "    interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
        "\n",
        "    user_features = pd.DataFrame()\n",
        "    user_features['user_id'] = interactions['user_id'].unique()\n",
        "\n",
        "    # 1. Время суток\n",
        "    interactions['hour'] = interactions['timestamp'].dt.hour\n",
        "\n",
        "    # Разбиваем на части дня\n",
        "    def get_time_of_day(hour):\n",
        "        if 5 <= hour < 12:\n",
        "            return 'morning'\n",
        "        elif 12 <= hour < 17:\n",
        "            return 'afternoon'\n",
        "        elif 17 <= hour < 22:\n",
        "            return 'evening'\n",
        "        else:\n",
        "            return 'night'\n",
        "\n",
        "    interactions['time_of_day'] = interactions['hour'].apply(get_time_of_day)\n",
        "\n",
        "    # Самое частое время активности\n",
        "    time_of_day_counts = interactions.groupby(['user_id', 'time_of_day']).size().reset_index(name='count')\n",
        "    user_primary_time = time_of_day_counts.loc[\n",
        "        time_of_day_counts.groupby('user_id')['count'].idxmax()\n",
        "    ][['user_id', 'time_of_day']].rename(columns={'time_of_day': 'user_primary_time_of_day'})\n",
        "\n",
        "    user_features = user_features.merge(user_primary_time, on='user_id', how='left')\n",
        "\n",
        "    # Распределение по времени суток\n",
        "    time_of_day_encoded = pd.get_dummies(interactions['time_of_day'], prefix='user_time_of_day')\n",
        "    time_of_day_encoded['user_id'] = interactions['user_id'].values\n",
        "\n",
        "    time_distribution = time_of_day_encoded.groupby('user_id').mean().reset_index()\n",
        "    user_features = user_features.merge(time_distribution, on='user_id', how='left')\n",
        "\n",
        "    # 2. Дни недели\n",
        "    interactions['day_of_week'] = interactions['timestamp'].dt.dayofweek\n",
        "    interactions['is_weekend'] = interactions['day_of_week'].isin([5, 6]).astype(int)\n",
        "\n",
        "    # Процент активности на выходных\n",
        "    weekend_stats = interactions.groupby('user_id')['is_weekend'].mean().reset_index(name='user_weekend_activity_ratio')\n",
        "    user_features = user_features.merge(weekend_stats, on='user_id', how='left')\n",
        "\n",
        "    # Флаг \"пользователь выходного дня\"\n",
        "    user_features['user_is_weekend_user'] = (user_features['user_weekend_activity_ratio'] > 0.5).astype(int)\n",
        "\n",
        "    # Распределение по дням недели\n",
        "    day_of_week_encoded = pd.get_dummies(interactions['day_of_week'], prefix='user_day_of_week')\n",
        "    day_of_week_encoded['user_id'] = interactions['user_id'].values\n",
        "\n",
        "    day_distribution = day_of_week_encoded.groupby('user_id').mean().reset_index()\n",
        "    user_features = user_features.merge(day_distribution, on='user_id', how='left')\n",
        "\n",
        "    # 3. Временные интервалы между действиями\n",
        "    interactions_sorted = interactions.sort_values(['user_id', 'timestamp'])\n",
        "    interactions_sorted['time_diff'] = interactions_sorted.groupby('user_id')['timestamp'].diff()\n",
        "\n",
        "    time_diff_stats = interactions_sorted[interactions_sorted['time_diff'].notna()].groupby('user_id')['time_diff'].agg([\n",
        "        'mean', 'median', 'std'\n",
        "    ]).reset_index()\n",
        "\n",
        "    time_diff_stats.columns = ['user_id', 'user_avg_time_between_actions',\n",
        "                              'user_median_time_between_actions', 'user_time_between_actions_std']\n",
        "\n",
        "    # Конвертируем в секунды\n",
        "    for col in ['user_avg_time_between_actions', 'user_median_time_between_actions',\n",
        "                'user_time_between_actions_std']:\n",
        "        time_diff_stats[col] = time_diff_stats[col].dt.total_seconds()\n",
        "\n",
        "    user_features = user_features.merge(time_diff_stats, on='user_id', how='left')\n",
        "\n",
        "    return user_features"
      ],
      "metadata": {
        "id": "mDA6MrBaJsr4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_demographic_features(users_meta_df, current_date=None):\n",
        "    \"\"\"\n",
        "    Создает демографические признаки пользователей.\n",
        "    \"\"\"\n",
        "    if users_meta_df is None:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    users_meta = users_meta_df.copy()\n",
        "    user_features = users_meta[['user_id']].copy()\n",
        "\n",
        "    if current_date is None:\n",
        "        current_date = datetime.now()\n",
        "\n",
        "    # 1. Возраст пользователя (если есть дата рождения)\n",
        "    if 'birth_date' in users_meta.columns:\n",
        "        users_meta['birth_date'] = pd.to_datetime(users_meta['birth_date'])\n",
        "        user_features['user_age'] = ((current_date - users_meta['birth_date']).dt.days / 365.25).astype(int)\n",
        "\n",
        "        # Возрастные группы\n",
        "        bins = [0, 18, 25, 35, 45, 55, 65, 100]\n",
        "        labels = ['<18', '18-25', '26-35', '36-45', '46-55', '56-65', '65+']\n",
        "        user_features['user_age_group'] = pd.cut(user_features['user_age'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "    # 2. Пол\n",
        "    if 'gender' in users_meta.columns:\n",
        "        user_features['user_gender'] = users_meta['gender'].fillna('unknown')\n",
        "        # One-hot encoding\n",
        "        gender_dummies = pd.get_dummies(user_features['user_gender'], prefix='user_gender')\n",
        "        user_features = pd.concat([user_features, gender_dummies], axis=1)\n",
        "\n",
        "    # 3. Локация\n",
        "    if 'city' in users_meta.columns:\n",
        "        user_features['user_city'] = users_meta['city'].fillna('unknown')\n",
        "\n",
        "    if 'country' in users_meta.columns:\n",
        "        user_features['user_country'] = users_meta['country'].fillna('unknown')\n",
        "\n",
        "        # Топ стран\n",
        "        top_countries = users_meta['country'].value_counts().head(20).index\n",
        "        user_features['user_is_top_country'] = user_features['user_country'].isin(top_countries).astype(int)\n",
        "\n",
        "    # 4. Дата регистрации\n",
        "    if 'registration_date' in users_meta.columns:\n",
        "        users_meta['registration_date'] = pd.to_datetime(users_meta['registration_date'])\n",
        "        user_features['user_days_since_registration'] = (current_date - users_meta['registration_date']).dt.days\n",
        "\n",
        "        # Группы по давности регистрации\n",
        "        reg_bins = [0, 30, 90, 180, 365, 730, 1825, 10000]\n",
        "        reg_labels = ['<1m', '1-3m', '3-6m', '6-12m', '1-2y', '2-5y', '5y+']\n",
        "        user_features['user_registration_group'] = pd.cut(\n",
        "            user_features['user_days_since_registration'],\n",
        "            bins=reg_bins,\n",
        "            labels=reg_labels,\n",
        "            right=False\n",
        "        )\n",
        "\n",
        "    # 5. Доход (если есть)\n",
        "    if 'income' in users_meta.columns:\n",
        "        user_features['user_income'] = users_meta['income']\n",
        "\n",
        "        # Сегменты дохода\n",
        "        income_bins = [0, 30000, 60000, 100000, 150000, 300000, float('inf')]\n",
        "        income_labels = ['<30k', '30-60k', '60-100k', '100-150k', '150-300k', '300k+']\n",
        "        user_features['user_income_segment'] = pd.cut(\n",
        "            user_features['user_income'],\n",
        "            bins=income_bins,\n",
        "            labels=income_labels,\n",
        "            right=False\n",
        "        )\n",
        "\n",
        "    # 6. Образование, профессия и т.д.\n",
        "    categorical_cols = ['education', 'occupation', 'marital_status', 'device_type']\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        if col in users_meta.columns:\n",
        "            user_features[f'user_{col}'] = users_meta[col].fillna('unknown')\n",
        "\n",
        "    return user_features"
      ],
      "metadata": {
        "id": "vJ6yEqT6JuSB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_item_interaction_features(interactions_df, current_date=None):\n",
        "    \"\"\"\n",
        "    Создает признаки взаимодействия пользователь-объект.\n",
        "    \"\"\"\n",
        "    if current_date is None:\n",
        "        current_date = interactions_df['timestamp'].max()\n",
        "    else:\n",
        "        current_date = pd.to_datetime(current_date)\n",
        "\n",
        "    interactions = interactions_df.copy()\n",
        "    interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
        "\n",
        "    # Создаем базовый DataFrame со всеми парами user-item\n",
        "    user_item_pairs = interactions[['user_id', 'item_id']].drop_duplicates()\n",
        "\n",
        "    # 1. Количество взаимодействий с конкретным объектом\n",
        "    interaction_counts = interactions.groupby(['user_id', 'item_id']).size().reset_index(name='user_item_interaction_count')\n",
        "    user_item_features = user_item_pairs.merge(interaction_counts, on=['user_id', 'item_id'], how='left')\n",
        "    user_item_features['user_item_interaction_count'] = user_item_features['user_item_interaction_count'].fillna(0).astype(int)\n",
        "\n",
        "    # 2. Временные признаки взаимодействия\n",
        "    time_stats = interactions.groupby(['user_id', 'item_id'])['timestamp'].agg([\n",
        "        'min', 'max', 'count'\n",
        "    ]).reset_index()\n",
        "\n",
        "    time_stats.columns = ['user_id', 'item_id', 'user_item_first_interaction',\n",
        "                         'user_item_last_interaction', 'interaction_count_check']\n",
        "\n",
        "    user_item_features = user_item_features.merge(\n",
        "        time_stats[['user_id', 'item_id', 'user_item_first_interaction', 'user_item_last_interaction']],\n",
        "        on=['user_id', 'item_id'], how='left'\n",
        "    )\n",
        "\n",
        "    # Дни с первого и последнего взаимодействия\n",
        "    user_item_features['user_item_first_interaction_days_ago'] = (\n",
        "        current_date - user_item_features['user_item_first_interaction']\n",
        "    ).dt.days.fillna(9999).astype(int)\n",
        "\n",
        "    user_item_features['user_item_last_interaction_days_ago'] = (\n",
        "        current_date - user_item_features['user_item_last_interaction']\n",
        "    ).dt.days.fillna(9999).astype(int)\n",
        "\n",
        "    # 3. Средний рейтинг пользователя объекту\n",
        "    if 'rating' in interactions.columns:\n",
        "        avg_rating = interactions[interactions['rating'].notna()].groupby(['user_id', 'item_id'])['rating'].mean().reset_index(name='user_item_avg_rating')\n",
        "        user_item_features = user_item_features.merge(avg_rating, on=['user_id', 'item_id'], how='left')\n",
        "        user_item_features['user_item_avg_rating'] = user_item_features['user_item_avg_rating'].fillna(0)\n",
        "\n",
        "    # 4. Типы взаимодействий (если есть interaction_type)\n",
        "    if 'interaction_type' in interactions.columns:\n",
        "        # Количество взаимодействий по типам\n",
        "        interaction_type_counts = interactions.groupby(['user_id', 'item_id', 'interaction_type']).size().unstack(fill_value=0).reset_index()\n",
        "\n",
        "        # Переименовываем колонки\n",
        "        interaction_type_counts.columns = [f'user_item_{col}_count' if col != 'user_id' and col != 'item_id' else col\n",
        "                                          for col in interaction_type_counts.columns]\n",
        "\n",
        "        user_item_features = user_item_features.merge(interaction_type_counts, on=['user_id', 'item_id'], how='left')\n",
        "\n",
        "        # Заполняем пропуски нулями\n",
        "        for col in interaction_type_counts.columns:\n",
        "            if col not in ['user_id', 'item_id']:\n",
        "                user_item_features[col] = user_item_features[col].fillna(0).astype(int)\n",
        "\n",
        "    # 5. Интенсивность взаимодействий (взаимодействий в день)\n",
        "    user_item_features['user_item_interaction_intensity'] = np.where(\n",
        "        user_item_features['user_item_first_interaction_days_ago'] < 9999,\n",
        "        user_item_features['user_item_interaction_count'] /\n",
        "        (user_item_features['user_item_first_interaction_days_ago'] + 1),\n",
        "        0\n",
        "    )\n",
        "\n",
        "    # 6. Флаги повторного взаимодействия\n",
        "    user_item_features['user_item_has_repeated_interaction'] = (user_item_features['user_item_interaction_count'] > 1).astype(int)\n",
        "    user_item_features['user_item_is_first_interaction_recent'] = (user_item_features['user_item_first_interaction_days_ago'] <= 7).astype(int)\n",
        "\n",
        "    return user_item_features"
      ],
      "metadata": {
        "id": "BCf6G_bfKKsx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_item_matching_features(user_features, item_features, interactions_df, items_meta_df):\n",
        "    \"\"\"\n",
        "    Создает признаки совпадения профилей пользователя и объекта.\n",
        "    \"\"\"\n",
        "    # Базовый DataFrame с парами user-item\n",
        "    user_item_pairs = interactions_df[['user_id', 'item_id']].drop_duplicates()\n",
        "\n",
        "    matching_features = user_item_pairs.copy()\n",
        "\n",
        "    # 1. Совпадение категории\n",
        "    if 'user_preferred_category' in user_features.columns and 'item_category' in item_features.columns:\n",
        "        # Получаем категории пользователей и объектов\n",
        "        user_categories = user_features[['user_id', 'user_preferred_category']]\n",
        "        item_categories = item_features[['item_id', 'item_category']]\n",
        "\n",
        "        # Объединяем\n",
        "        matching_data = matching_features.merge(user_categories, on='user_id', how='left')\n",
        "        matching_data = matching_data.merge(item_categories, on='item_id', how='left')\n",
        "\n",
        "        matching_data['category_match'] = (matching_data['user_preferred_category'] == matching_data['item_category']).astype(int)\n",
        "        matching_data['preferred_category_match'] = matching_data['category_match']  # Для данного примера\n",
        "\n",
        "        matching_features = matching_features.merge(\n",
        "            matching_data[['user_id', 'item_id', 'category_match', 'preferred_category_match']],\n",
        "            on=['user_id', 'item_id'], how='left'\n",
        "        )\n",
        "\n",
        "    # 2. Совпадение ценового сегмента\n",
        "    if 'user_preferred_price_median' in user_features.columns and 'item_price' in item_features.columns:\n",
        "        user_prices = user_features[['user_id', 'user_preferred_price_median', 'user_price_std']]\n",
        "        item_prices = item_features[['item_id', 'item_price']]\n",
        "\n",
        "        price_data = matching_features.merge(user_prices, on='user_id', how='left')\n",
        "        price_data = price_data.merge(item_prices, on='item_id', how='left')\n",
        "\n",
        "        # Разница между ценой объекта и предпочитаемой ценой пользователя\n",
        "        price_data['price_diff'] = price_data['item_price'] - price_data['user_preferred_price_median']\n",
        "        price_data['price_diff_abs'] = price_data['price_diff'].abs()\n",
        "\n",
        "        # Нормализованная разница (в стандартных отклонениях)\n",
        "        price_data['price_diff_norm'] = np.where(\n",
        "            price_data['user_price_std'] > 0,\n",
        "            price_data['price_diff_abs'] / price_data['user_price_std'],\n",
        "            0\n",
        "        )\n",
        "\n",
        "        # Бинарный признак совпадения (в пределах 1.5 стандартных отклонений)\n",
        "        price_data['price_match'] = (price_data['price_diff_norm'] <= 1.5).astype(int)\n",
        "\n",
        "        matching_features = matching_features.merge(\n",
        "            price_data[['user_id', 'item_id', 'price_diff', 'price_diff_abs', 'price_diff_norm', 'price_match']],\n",
        "            on=['user_id', 'item_id'], how='left'\n",
        "        )\n",
        "\n",
        "    # 3. Совпадение бренда\n",
        "    if 'user_preferred_brand' in user_features.columns and 'item_brand' in item_features.columns:\n",
        "        user_brands = user_features[['user_id', 'user_preferred_brand']]\n",
        "        item_brands = item_features[['item_id', 'item_brand']]\n",
        "\n",
        "        brand_data = matching_features.merge(user_brands, on='user_id', how='left')\n",
        "        brand_data = brand_data.merge(item_brands, on='item_id', how='left')\n",
        "\n",
        "        brand_data['brand_match'] = (brand_data['user_preferred_brand'] == brand_data['item_brand']).astype(int)\n",
        "\n",
        "        matching_features = matching_features.merge(\n",
        "            brand_data[['user_id', 'item_id', 'brand_match']],\n",
        "            on=['user_id', 'item_id'], how='left'\n",
        "        )\n",
        "\n",
        "    # 4. Историческое взаимодействие с категорией/брендом\n",
        "    interactions_with_meta = interactions_df.merge(\n",
        "        items_meta_df[['item_id', 'category', 'brand']],\n",
        "        on='item_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Взаимодействие с категорией\n",
        "    if 'category' in interactions_with_meta.columns:\n",
        "        user_category_interaction = interactions_with_meta.groupby(['user_id', 'category']).size().reset_index(name='category_interaction_count')\n",
        "        user_category_interaction['user_has_category_interaction'] = 1\n",
        "\n",
        "        # Добавляем к matching_features\n",
        "        matching_data_with_cat = matching_features.merge(\n",
        "            item_features[['item_id', 'item_category']],\n",
        "            on='item_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        matching_data_with_cat = matching_data_with_cat.merge(\n",
        "            user_category_interaction[['user_id', 'category', 'user_has_category_interaction', 'category_interaction_count']],\n",
        "            left_on=['user_id', 'item_category'],\n",
        "            right_on=['user_id', 'category'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        matching_features['user_has_category_interaction'] = matching_data_with_cat['user_has_category_interaction'].fillna(0).astype(int)\n",
        "        matching_features['user_category_interaction_count'] = matching_data_with_cat['category_interaction_count'].fillna(0)\n",
        "\n",
        "    return matching_features"
      ],
      "metadata": {
        "id": "I1O1BR4JKNMD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_user_item_matching_features(user_features, item_features, interactions_df, items_meta_df):\n",
        "    \"\"\"\n",
        "    Создает признаки совпадения профилей пользователя и объекта.\n",
        "    \"\"\"\n",
        "    # Базовый DataFrame с парами user-item\n",
        "    user_item_pairs = interactions_df[['user_id', 'item_id']].drop_duplicates()\n",
        "\n",
        "    matching_features = user_item_pairs.copy()\n",
        "\n",
        "    # 1. Совпадение категории\n",
        "    if 'user_preferred_category' in user_features.columns and 'item_category' in item_features.columns:\n",
        "        # Получаем категории пользователей и объектов\n",
        "        user_categories = user_features[['user_id', 'user_preferred_category']]\n",
        "        item_categories = item_features[['item_id', 'item_category']]\n",
        "\n",
        "        # Объединяем\n",
        "        matching_data = matching_features.merge(user_categories, on='user_id', how='left')\n",
        "        matching_data = matching_data.merge(item_categories, on='item_id', how='left')\n",
        "\n",
        "        matching_data['category_match'] = (matching_data['user_preferred_category'] == matching_data['item_category']).astype(int)\n",
        "        matching_data['preferred_category_match'] = matching_data['category_match']  # Для данного примера\n",
        "\n",
        "        matching_features = matching_features.merge(\n",
        "            matching_data[['user_id', 'item_id', 'category_match', 'preferred_category_match']],\n",
        "            on=['user_id', 'item_id'], how='left'\n",
        "        )\n",
        "\n",
        "    # 2. Совпадение ценового сегмента\n",
        "    if 'user_preferred_price_median' in user_features.columns and 'item_price' in item_features.columns:\n",
        "        user_prices = user_features[['user_id', 'user_preferred_price_median', 'user_price_std']]\n",
        "        item_prices = item_features[['item_id', 'item_price']]\n",
        "\n",
        "        price_data = matching_features.merge(user_prices, on='user_id', how='left')\n",
        "        price_data = price_data.merge(item_prices, on='item_id', how='left')\n",
        "\n",
        "        # Разница между ценой объекта и предпочитаемой ценой пользователя\n",
        "        price_data['price_diff'] = price_data['item_price'] - price_data['user_preferred_price_median']\n",
        "        price_data['price_diff_abs'] = price_data['price_diff'].abs()\n",
        "\n",
        "        # Нормализованная разница (в стандартных отклонениях)\n",
        "        price_data['price_diff_norm'] = np.where(\n",
        "            price_data['user_price_std'] > 0,\n",
        "            price_data['price_diff_abs'] / price_data['user_price_std'],\n",
        "            0\n",
        "        )\n",
        "\n",
        "        # Бинарный признак совпадения (в пределах 1.5 стандартных отклонений)\n",
        "        price_data['price_match'] = (price_data['price_diff_norm'] <= 1.5).astype(int)\n",
        "\n",
        "        matching_features = matching_features.merge(\n",
        "            price_data[['user_id', 'item_id', 'price_diff', 'price_diff_abs', 'price_diff_norm', 'price_match']],\n",
        "            on=['user_id', 'item_id'], how='left'\n",
        "        )\n",
        "\n",
        "    # 3. Совпадение бренда\n",
        "    if 'user_preferred_brand' in user_features.columns and 'item_brand' in item_features.columns:\n",
        "        user_brands = user_features[['user_id', 'user_preferred_brand']]\n",
        "        item_brands = item_features[['item_id', 'item_brand']]\n",
        "\n",
        "        brand_data = matching_features.merge(user_brands, on='user_id', how='left')\n",
        "        brand_data = brand_data.merge(item_brands, on='item_id', how='left')\n",
        "\n",
        "        brand_data['brand_match'] = (brand_data['user_preferred_brand'] == brand_data['item_brand']).astype(int)\n",
        "\n",
        "        matching_features = matching_features.merge(\n",
        "            brand_data[['user_id', 'item_id', 'brand_match']],\n",
        "            on=['user_id', 'item_id'], how='left'\n",
        "        )\n",
        "\n",
        "    # 4. Историческое взаимодействие с категорией/брендом\n",
        "    interactions_with_meta = interactions_df.merge(\n",
        "        items_meta_df[['item_id', 'category', 'brand']],\n",
        "        on='item_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Взаимодействие с категорией\n",
        "    if 'category' in interactions_with_meta.columns:\n",
        "        user_category_interaction = interactions_with_meta.groupby(['user_id', 'category']).size().reset_index(name='category_interaction_count')\n",
        "        user_category_interaction['user_has_category_interaction'] = 1\n",
        "\n",
        "        # Добавляем к matching_features\n",
        "        matching_data_with_cat = matching_features.merge(\n",
        "            item_features[['item_id', 'item_category']],\n",
        "            on='item_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        matching_data_with_cat = matching_data_with_cat.merge(\n",
        "            user_category_interaction[['user_id', 'category', 'user_has_category_interaction', 'category_interaction_count']],\n",
        "            left_on=['user_id', 'item_category'],\n",
        "            right_on=['user_id', 'category'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        matching_features['user_has_category_interaction'] = matching_data_with_cat['user_has_category_interaction'].fillna(0).astype(int)\n",
        "        matching_features['user_category_interaction_count'] = matching_data_with_cat['category_interaction_count'].fillna(0)\n",
        "\n",
        "    return matching_features"
      ],
      "metadata": {
        "id": "l31FYFk8KOxD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_similarity_based_features(user_features, item_features, interactions_df,\n",
        "                                   user_similarity_matrix=None, item_similarity_matrix=None,\n",
        "                                   n_similar=10):\n",
        "    \"\"\"\n",
        "    Создает признаки на основе похожих объектов и пользователей.\n",
        "    \"\"\"\n",
        "    user_item_pairs = interactions_df[['user_id', 'item_id']].drop_duplicates()\n",
        "    similarity_features = user_item_pairs.copy()\n",
        "\n",
        "    # 1. Признаки на основе похожих объектов\n",
        "    if item_similarity_matrix is not None and 'user_item_interaction_count' in interactions_df.columns:\n",
        "        print(\"Создание признаков на основе похожих объектов...\")\n",
        "\n",
        "        # Получаем историю взаимодействий пользователей\n",
        "        user_history = interactions_df.groupby(['user_id', 'item_id'])['user_item_interaction_count'].sum().reset_index()\n",
        "\n",
        "        # Для каждой пары user-item считаем статистики по похожим объектам\n",
        "        similar_items_stats = []\n",
        "\n",
        "        for idx, row in user_item_pairs.iterrows():\n",
        "            user_id = row['user_id']\n",
        "            item_id = row['item_id']\n",
        "\n",
        "            # Находим N самых похожих объектов\n",
        "            if item_id in item_similarity_matrix.index:\n",
        "                similar_items = item_similarity_matrix.loc[item_id].nlargest(n_similar + 1)[1:]  # Исключаем сам объект\n",
        "                similar_item_ids = similar_items.index.tolist()\n",
        "\n",
        "                # История пользователя с похожими объектами\n",
        "                user_similar_history = user_history[\n",
        "                    (user_history['user_id'] == user_id) &\n",
        "                    (user_history['item_id'].isin(similar_item_ids))\n",
        "                ]\n",
        "\n",
        "                # Агрегируем статистики\n",
        "                if not user_similar_history.empty:\n",
        "                    avg_rating_similar = user_similar_history['user_item_interaction_count'].mean()\n",
        "                    total_interactions_similar = user_similar_history['user_item_interaction_count'].sum()\n",
        "                else:\n",
        "                    avg_rating_similar = 0\n",
        "                    total_interactions_similar = 0\n",
        "\n",
        "                similar_items_stats.append({\n",
        "                    'user_id': user_id,\n",
        "                    'item_id': item_id,\n",
        "                    'user_avg_rating_on_similar_items': avg_rating_similar,\n",
        "                    'user_interaction_count_with_similar_items': total_interactions_similar\n",
        "                })\n",
        "\n",
        "            if idx % 1000 == 0 and idx > 0:\n",
        "                print(f\"Обработано {idx} пар...\")\n",
        "\n",
        "        similar_stats_df = pd.DataFrame(similar_items_stats)\n",
        "        similarity_features = similarity_features.merge(similar_stats_df, on=['user_id', 'item_id'], how='left')\n",
        "\n",
        "    # 2. Признаки на основе похожих пользователей\n",
        "    if user_similarity_matrix is not None:\n",
        "        print(\"Создание признаков на основе похожих пользователей...\")\n",
        "\n",
        "        # Получаем популярность объектов среди пользователей\n",
        "        item_popularity = interactions_df.groupby('item_id')['user_item_interaction_count'].sum().reset_index(name='item_popularity_total')\n",
        "\n",
        "        similar_users_stats = []\n",
        "\n",
        "        for idx, row in user_item_pairs.iterrows():\n",
        "            user_id = row['user_id']\n",
        "            item_id = row['item_id']\n",
        "\n",
        "            # Находим K самых похожих пользователей\n",
        "            if user_id in user_similarity_matrix.index:\n",
        "                similar_users = user_similarity_matrix.loc[user_id].nlargest(n_similar + 1)[1:]  # Исключаем самого пользователя\n",
        "                similar_user_ids = similar_users.index.tolist()\n",
        "\n",
        "                # Взаимодействия похожих пользователей с данным объектом\n",
        "                similar_users_interactions = interactions_df[\n",
        "                    (interactions_df['user_id'].isin(similar_user_ids)) &\n",
        "                    (interactions_df['item_id'] == item_id)\n",
        "                ]\n",
        "\n",
        "                # Агрегируем статистики\n",
        "                if not similar_users_interactions.empty:\n",
        "                    avg_popularity_similar = similar_users_interactions['user_item_interaction_count'].mean()\n",
        "                    avg_rating_similar = similar_users_interactions['rating'].mean() if 'rating' in similar_users_interactions.columns else 0\n",
        "                else:\n",
        "                    avg_popularity_similar = 0\n",
        "                    avg_rating_similar = 0\n",
        "\n",
        "                similar_users_stats.append({\n",
        "                    'user_id': user_id,\n",
        "                    'item_id': item_id,\n",
        "                    'avg_popularity_of_item_among_similar_users': avg_popularity_similar,\n",
        "                    'avg_rating_of_item_among_similar_users': avg_rating_similar\n",
        "                })\n",
        "\n",
        "            if idx % 1000 == 0 and idx > 0:\n",
        "                print(f\"Обработано {idx} пар...\")\n",
        "\n",
        "        similar_users_df = pd.DataFrame(similar_users_stats)\n",
        "        similarity_features = similarity_features.merge(similar_users_df, on=['user_id', 'item_id'], how='left')\n",
        "\n",
        "    return similarity_features"
      ],
      "metadata": {
        "id": "y-uYfrNmK-bI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_rank_features(user_item_pairs, user_features, item_features, interactions_df, items_meta_df):\n",
        "    \"\"\"\n",
        "    Создает ранговые признаки для пар пользователь-объект.\n",
        "    \"\"\"\n",
        "    rank_features = user_item_pairs.copy()\n",
        "\n",
        "    # 1. Ранг популярности объекта в категории пользователя\n",
        "    if 'user_preferred_category' in user_features.columns and 'item_category' in item_features.columns:\n",
        "        # Получаем категорию объекта и популярность\n",
        "        item_popularity = interactions_df.groupby('item_id').size().reset_index(name='item_popularity')\n",
        "\n",
        "        # Добавляем категории объектов\n",
        "        item_popularity_with_cat = item_popularity.merge(\n",
        "            item_features[['item_id', 'item_category']],\n",
        "            on='item_id',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Считаем ранг популярности внутри каждой категории\n",
        "        item_popularity_with_cat['item_popularity_rank_in_category'] = item_popularity_with_cat.groupby('item_category')['item_popularity'].rank(method='dense', ascending=False)\n",
        "\n",
        "        # Для каждой пары user-item определяем ранг\n",
        "        user_preferred_cats = user_features[['user_id', 'user_preferred_category']]\n",
        "\n",
        "        rank_data = rank_features.merge(user_preferred_cats, on='user_id', how='left')\n",
        "        rank_data = rank_data.merge(\n",
        "            item_popularity_with_cat[['item_id', 'item_category', 'item_popularity_rank_in_category']],\n",
        "            on='item_id', how='left'\n",
        "        )\n",
        "\n",
        "        # Ранг в предпочитаемой категории пользователя\n",
        "        rank_data['item_popularity_rank_in_user_category'] = np.where(\n",
        "            rank_data['user_preferred_category'] == rank_data['item_category'],\n",
        "            rank_data['item_popularity_rank_in_category'],\n",
        "            999  # Если категория не совпадает, ставим высокий ранг\n",
        "        )\n",
        "\n",
        "        rank_features = rank_features.merge(\n",
        "            rank_data[['user_id', 'item_id', 'item_popularity_rank_in_user_category']],\n",
        "            on=['user_id', 'item_id'], how='left'\n",
        "        )\n",
        "\n",
        "    # 2. Ранг активности пользователя\n",
        "    if 'user_activity_rank' in user_features.columns:\n",
        "        user_ranks = user_features[['user_id', 'user_activity_rank']]\n",
        "        rank_features = rank_features.merge(user_ranks, on='user_id', how='left')\n",
        "\n",
        "    # 3. Относительный ранг цены объекта для пользователя\n",
        "    if 'user_preferred_price_median' in user_features.columns and 'item_price' in item_features.columns:\n",
        "        user_prices = user_features[['user_id', 'user_preferred_price_median', 'user_min_price', 'user_max_price']]\n",
        "        item_prices = item_features[['item_id', 'item_price']]\n",
        "\n",
        "        price_rank_data = rank_features.merge(user_prices, on='user_id', how='left')\n",
        "        price_rank_data = price_rank_data.merge(item_prices, on='item_id', how='left')\n",
        "\n",
        "        # Ранг цены относительно предпочтений пользователя\n",
        "        price_rank_data['price_rank_for_user'] = np.where(\n",
        "            price_rank_data['item_price'] < price_rank_data['user_preferred_price_median'],\n",
        "            'below_preferred',\n",
        "            np.where(\n",
        "                price_rank_data['item_price'] > price_rank_data['user_preferred_price_median'],\n",
        "                'above_preferred',\n",
        "                'at_preferred'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Кодируем\n",
        "        price_rank_encoded = pd.get_dummies(price_rank_data['price_rank_for_user'], prefix='price_rank')\n",
        "        price_rank_encoded[['user_id', 'item_id']] = price_rank_data[['user_id', 'item_id']].values\n",
        "\n",
        "        rank_features = rank_features.merge(\n",
        "            price_rank_encoded,\n",
        "            on=['user_id', 'item_id'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "    # 4. Квантили разницы во времени\n",
        "    if 'user_item_last_interaction_days_ago' in rank_features.columns:\n",
        "        rank_features['recency_quantile'] = pd.qcut(\n",
        "            rank_features['user_item_last_interaction_days_ago'],\n",
        "            q=5,\n",
        "            labels=['very_old', 'old', 'medium', 'recent', 'very_recent']\n",
        "        )\n",
        "\n",
        "    return rank_features"
      ],
      "metadata": {
        "id": "-CML-okTLAYx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_all_user_item_features(interactions_df, user_features, item_features,\n",
        "                                items_meta_df, current_date=None,\n",
        "                                user_similarity_matrix=None, item_similarity_matrix=None):\n",
        "    \"\"\"\n",
        "    Создает все признаки для пар пользователь-объект.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"СОЗДАНИЕ ПРИЗНАКОВ USER-ITEM ВЗАИМОДЕЙСТВИЙ\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    print(\"1. Создание базовых признаков взаимодействия...\")\n",
        "    interaction_features = create_user_item_interaction_features(interactions_df, current_date)\n",
        "\n",
        "    print(\"2. Создание признаков совпадения профилей...\")\n",
        "    matching_features = create_user_item_matching_features(\n",
        "        user_features, item_features, interactions_df, items_meta_df\n",
        "    )\n",
        "\n",
        "    print(\"3. Создание признаков на основе похожих объектов/пользователей...\")\n",
        "    similarity_features = create_similarity_based_features(\n",
        "        user_features, item_features, interactions_df,\n",
        "        user_similarity_matrix, item_similarity_matrix\n",
        "    )\n",
        "\n",
        "    print(\"4. Создание ранговых признаков...\")\n",
        "    rank_features = create_rank_features(\n",
        "        interactions_df[['user_id', 'item_id']].drop_duplicates(),\n",
        "        user_features, item_features, interactions_df, items_meta_df\n",
        "    )\n",
        "\n",
        "    print(\"5. Объединение всех признаков...\")\n",
        "    # Объединяем все признаки\n",
        "    all_user_item_features = interaction_features.copy()\n",
        "\n",
        "    for features_df in [matching_features, similarity_features, rank_features]:\n",
        "        all_user_item_features = all_user_item_features.merge(\n",
        "            features_df,\n",
        "            on=['user_id', 'item_id'],\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "    # Заполняем пропуски\n",
        "    print(\"6. Заполнение пропусков...\")\n",
        "    numeric_cols = all_user_item_features.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    for col in numeric_cols:\n",
        "        if col not in ['user_id', 'item_id']:\n",
        "            all_user_item_features[col] = all_user_item_features[col].fillna(0)\n",
        "\n",
        "    print(f\"Создано признаков user-item: {all_user_item_features.shape[1] - 2}\")\n",
        "    print(f\"Количество пар user-item: {all_user_item_features.shape[0]}\")\n",
        "\n",
        "    return all_user_item_features"
      ],
      "metadata": {
        "id": "rRSROKqrL4CC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_all_user_features(interactions_df, users_meta_df=None, items_meta_df=None, current_date=None):\n",
        "    \"\"\"\n",
        "    Создает все признаки пользователей.\n",
        "    \"\"\"\n",
        "    print(\"Создание признаков активности пользователей...\")\n",
        "    activity_features = create_user_activity_features(interactions_df, users_meta_df, current_date)\n",
        "\n",
        "    print(\"Создание поведенческих признаков...\")\n",
        "    behavioral_features = create_user_behavioral_features(interactions_df, items_meta_df)\n",
        "\n",
        "    print(\"Создание временных паттернов...\")\n",
        "    temporal_features = create_user_temporal_patterns(interactions_df)\n",
        "\n",
        "    print(\"Создание демографических признаков...\")\n",
        "    demographic_features = create_user_demographic_features(users_meta_df, current_date)\n",
        "\n",
        "    # Объединяем все признаки\n",
        "    print(\"Объединение всех признаков пользователей...\")\n",
        "    user_features = activity_features.copy()\n",
        "\n",
        "    for features_df in [behavioral_features, temporal_features, demographic_features]:\n",
        "        if not features_df.empty:\n",
        "            user_features = user_features.merge(features_df, on='user_id', how='left')\n",
        "\n",
        "    # Добавляем ранговые признаки\n",
        "    print(\"Добавление ранговых признаков...\")\n",
        "    user_features = add_user_rank_features(user_features, interactions_df)\n",
        "\n",
        "    print(f\"Создано признаков пользователей: {user_features.shape[1] - 1}\")\n",
        "    print(f\"Количество пользователей: {user_features.shape[0]}\")\n",
        "\n",
        "    return user_features\n",
        "\n",
        "def add_user_rank_features(user_features, interactions_df):\n",
        "    \"\"\"\n",
        "    Добавляет ранговые признаки.\n",
        "    \"\"\"\n",
        "    user_features_ranked = user_features.copy()\n",
        "\n",
        "    # 1. Ранг по активности среди всех пользователей\n",
        "    if 'user_activity_count' in user_features_ranked.columns:\n",
        "        user_features_ranked['user_activity_rank'] = user_features_ranked['user_activity_count'].rank(pct=True)\n",
        "\n",
        "    # 2. Ранг по частоте\n",
        "    if 'user_activity_frequency' in user_features_ranked.columns:\n",
        "        user_features_ranked['user_frequency_rank'] = user_features_ranked['user_activity_frequency'].rank(pct=True)\n",
        "\n",
        "    # 3. Ранг по давности (чем меньше дней с последнего визита, тем выше ранг)\n",
        "    if 'user_recency_days' in user_features_ranked.columns:\n",
        "        user_features_ranked['user_recency_rank'] = (-user_features_ranked['user_recency_days']).rank(pct=True)\n",
        "\n",
        "    # 4. Ранг по диверсификации\n",
        "    if 'user_diversity' in user_features_ranked.columns:\n",
        "        user_features_ranked['user_diversity_rank'] = user_features_ranked['user_diversity'].rank(pct=True)\n",
        "\n",
        "    # 5. Квантили активности\n",
        "    if 'user_activity_count' in user_features_ranked.columns:\n",
        "        activity_quantiles = pd.qcut(\n",
        "            user_features_ranked['user_activity_count'],\n",
        "            q=5,\n",
        "            labels=['very_low', 'low', 'medium', 'high', 'very_high']\n",
        "        )\n",
        "        user_features_ranked['user_activity_quantile'] = activity_quantiles\n",
        "\n",
        "    return user_features_ranked"
      ],
      "metadata": {
        "id": "Gws_uwMvMBKz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy"
      ],
      "metadata": {
        "id": "inDs8ZZUMH-b"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем синтетические данные\n",
        "np.random.seed(42)\n",
        "\n",
        "# Взаимодействия\n",
        "n_interactions = 50000\n",
        "n_users = 1000\n",
        "n_items = 500\n",
        "\n",
        "interactions_data = {\n",
        "    'user_id': np.random.randint(1, n_users+1, n_interactions),\n",
        "    'item_id': np.random.randint(1, n_items+1, n_interactions),\n",
        "    'rating': np.random.choice([1, 2, 3, 4, 5, np.nan], n_interactions, p=[0.05, 0.1, 0.15, 0.3, 0.3, 0.1]),\n",
        "    'interaction_type': np.random.choice(['click', 'view', 'purchase'], n_interactions, p=[0.6, 0.3, 0.1]),\n",
        "    'timestamp': pd.date_range(start='2024-01-01', periods=n_interactions, freq='H')\n",
        "}\n",
        "\n",
        "interactions_df = pd.DataFrame(interactions_data)\n",
        "\n",
        "# Метаданные пользователей\n",
        "users_data = {\n",
        "    'user_id': range(1, n_users+1),\n",
        "    'gender': np.random.choice(['M', 'F', 'unknown'], n_users, p=[0.45, 0.45, 0.1]),\n",
        "    'age': np.random.randint(18, 70, n_users),\n",
        "    'country': np.random.choice(['US', 'UK', 'DE', 'FR', 'RU'], n_users),\n",
        "    'registration_date': pd.date_range(start='2022-01-01', periods=n_users, freq='D')\n",
        "}\n",
        "\n",
        "users_meta_df = pd.DataFrame(users_data)\n",
        "\n",
        "# Метаданные объектов\n",
        "items_data = {\n",
        "    'item_id': range(1, n_items+1),\n",
        "    'category': np.random.choice(['Electronics', 'Books', 'Clothing', 'Home', 'Sports'], n_items),\n",
        "    'brand': np.random.choice(['Brand_A', 'Brand_B', 'Brand_C'], n_items),\n",
        "    'price': np.random.exponential(100, n_items).round(2)\n",
        "}\n",
        "\n",
        "items_meta_df = pd.DataFrame(items_data)\n",
        "\n",
        "# Создаем признаки\n",
        "print(\"СОЗДАНИЕ ПРИЗНАКОВ ПОЛЬЗОВАТЕЛЕЙ\")\n",
        "print(\"=\" * 50)\n",
        "user_features_df = create_all_user_features(\n",
        "    interactions_df=interactions_df,\n",
        "    users_meta_df=users_meta_df,\n",
        "    items_meta_df=items_meta_df,\n",
        "    current_date='2024-02-15'\n",
        ")\n",
        "\n",
        "print(\"\\nСОЗДАНИЕ ПРИЗНАКОВ USER-ITEM\")\n",
        "print(\"=\" * 50)\n",
        "user_item_features_df = create_all_user_item_features(\n",
        "    interactions_df=interactions_df,\n",
        "    user_features=user_features_df,\n",
        "    item_features=item_features_df,  # Предположим, что item_features_df уже создан\n",
        "    items_meta_df=items_meta_df,\n",
        "    current_date='2024-02-15'\n",
        ")\n",
        "\n",
        "print(\"\\nРезультат:\")\n",
        "print(f\"Признаков пользователей: {user_features_df.shape[1] - 1}\")\n",
        "print(f\"Признаков user-item: {user_item_features_df.shape[1] - 2}\")\n",
        "\n",
        "print(\"\\nПервые 5 строк user-item признаков:\")\n",
        "print(user_item_features_df.head())\n",
        "\n",
        "print(\"\\nКолонки user-item признаков:\")\n",
        "print(user_item_features_df.columns.tolist()[:20])  # Первые 20 колонок"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "sqaeIIseL51a",
        "outputId": "b561de5f-12bc-4246-d71e-6f67d789d200"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "СОЗДАНИЕ ПРИЗНАКОВ ПОЛЬЗОВАТЕЛЕЙ\n",
            "==================================================\n",
            "Создание признаков активности пользователей...\n",
            "Создание поведенческих признаков...\n",
            "Создание временных паттернов...\n",
            "Создание демографических признаков...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for -: 'DatetimeArray' and 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4013968952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"СОЗДАНИЕ ПРИЗНАКОВ ПОЛЬЗОВАТЕЛЕЙ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m user_features_df = create_all_user_features(\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0minteractions_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minteractions_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0musers_meta_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musers_meta_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4145596702.py\u001b[0m in \u001b[0;36mcreate_all_user_features\u001b[0;34m(interactions_df, users_meta_df, items_meta_df, current_date)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Создание демографических признаков...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdemographic_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_user_demographic_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_meta_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Объединяем все признаки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3431493556.py\u001b[0m in \u001b[0;36mcreate_user_demographic_features\u001b[0;34m(users_meta_df, current_date)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'registration_date'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0musers_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'registration_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'registration_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_days_since_registration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_date\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0musers_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'registration_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Группы по давности регистрации\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__rsub__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rsub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__mul__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_align_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexOpsMixin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_align_for_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_asobject\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;31m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# because numexpr will fail on it, see GH#31457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# TODO we should handle EAs consistently and move this check before the if/else\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/roperator.py\u001b[0m in \u001b[0;36mrsub\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrsub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36m__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0;31m# We get here with e.g. datetime objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1510\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'DatetimeArray' and 'str'"
          ]
        }
      ]
    }
  ]
}