{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "оценка от 0 до 5"
      ],
      "metadata": {
        "id": "9DawMnVlMroy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHlXkdrbIn6e",
        "outputId": "42af1a86-c4c8-42da-9a59-f858ad3fd8f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.693071186542511\n",
            "Epoch 2, Loss: 0.692124605178833\n",
            "Epoch 3, Loss: 0.6904391050338745\n",
            "Epoch 4, Loss: 0.6878796219825745\n",
            "Epoch 5, Loss: 0.6844171285629272\n",
            "Epoch 6, Loss: 0.6800409555435181\n",
            "Epoch 7, Loss: 0.6747444868087769\n",
            "Epoch 8, Loss: 0.6685162782669067\n",
            "Epoch 9, Loss: 0.6613413691520691\n",
            "Epoch 10, Loss: 0.653204619884491\n",
            "Epoch 11, Loss: 0.6440922617912292\n",
            "Epoch 12, Loss: 0.6339951753616333\n",
            "Epoch 13, Loss: 0.6229115724563599\n",
            "Epoch 14, Loss: 0.6108473539352417\n",
            "Epoch 15, Loss: 0.5978164076805115\n",
            "Epoch 16, Loss: 0.5838404893875122\n",
            "Epoch 17, Loss: 0.5689497590065002\n",
            "Epoch 18, Loss: 0.5531820058822632\n",
            "Epoch 19, Loss: 0.5365827083587646\n",
            "Epoch 20, Loss: 0.5192041993141174\n",
            "Epoch 21, Loss: 0.5011062622070312\n",
            "Epoch 22, Loss: 0.4823554456233978\n",
            "Epoch 23, Loss: 0.46302616596221924\n",
            "Epoch 24, Loss: 0.4432011842727661\n",
            "Epoch 25, Loss: 0.42297205328941345\n",
            "Epoch 26, Loss: 0.40243929624557495\n",
            "Epoch 27, Loss: 0.38171207904815674\n",
            "Epoch 28, Loss: 0.3609068989753723\n",
            "Epoch 29, Loss: 0.3401457369327545\n",
            "Epoch 30, Loss: 0.31955379247665405\n",
            "Epoch 31, Loss: 0.29925644397735596\n",
            "Epoch 32, Loss: 0.2793758809566498\n",
            "Epoch 33, Loss: 0.2600281536579132\n",
            "Epoch 34, Loss: 0.2413194179534912\n",
            "Epoch 35, Loss: 0.2233431488275528\n",
            "Epoch 36, Loss: 0.20617805421352386\n",
            "Epoch 37, Loss: 0.18988637626171112\n",
            "Epoch 38, Loss: 0.17451341450214386\n",
            "Epoch 39, Loss: 0.16008791327476501\n",
            "Epoch 40, Loss: 0.14662259817123413\n",
            "Epoch 41, Loss: 0.13411574065685272\n",
            "Epoch 42, Loss: 0.12255267798900604\n",
            "Epoch 43, Loss: 0.11190774291753769\n",
            "Epoch 44, Loss: 0.10214613378047943\n",
            "Epoch 45, Loss: 0.09322594106197357\n",
            "Epoch 46, Loss: 0.08510001748800278\n",
            "Epoch 47, Loss: 0.07771782577037811\n",
            "Epoch 48, Loss: 0.07102690637111664\n",
            "Epoch 49, Loss: 0.06497430801391602\n",
            "Epoch 50, Loss: 0.0595078207552433\n",
            "Epoch 51, Loss: 0.05457659810781479\n",
            "Epoch 52, Loss: 0.05013210326433182\n",
            "Epoch 53, Loss: 0.04612850397825241\n",
            "Epoch 54, Loss: 0.04252295568585396\n",
            "Epoch 55, Loss: 0.03927569091320038\n",
            "Epoch 56, Loss: 0.03635032847523689\n",
            "Epoch 57, Loss: 0.03371349349617958\n",
            "Epoch 58, Loss: 0.03133498877286911\n",
            "Epoch 59, Loss: 0.029187489300966263\n",
            "Epoch 60, Loss: 0.027246467769145966\n",
            "Epoch 61, Loss: 0.025489866733551025\n",
            "Epoch 62, Loss: 0.023898089304566383\n",
            "Epoch 63, Loss: 0.022453466430306435\n",
            "Epoch 64, Loss: 0.021140415221452713\n",
            "Epoch 65, Loss: 0.019945064559578896\n",
            "Epoch 66, Loss: 0.018855035305023193\n",
            "Epoch 67, Loss: 0.017859358340501785\n",
            "Epoch 68, Loss: 0.016948262229561806\n",
            "Epoch 69, Loss: 0.016113130375742912\n",
            "Epoch 70, Loss: 0.01534622348845005\n",
            "Epoch 71, Loss: 0.014640740118920803\n",
            "Epoch 72, Loss: 0.013990591280162334\n",
            "Epoch 73, Loss: 0.013390317559242249\n",
            "Epoch 74, Loss: 0.01283514965325594\n",
            "Epoch 75, Loss: 0.01232071127742529\n",
            "Epoch 76, Loss: 0.011843211948871613\n",
            "Epoch 77, Loss: 0.011399148032069206\n",
            "Epoch 78, Loss: 0.010985510423779488\n",
            "Epoch 79, Loss: 0.010599528439342976\n",
            "Epoch 80, Loss: 0.010238679125905037\n",
            "Epoch 81, Loss: 0.009900780394673347\n",
            "Epoch 82, Loss: 0.009583868086338043\n",
            "Epoch 83, Loss: 0.009286136366426945\n",
            "Epoch 84, Loss: 0.009005905129015446\n",
            "Epoch 85, Loss: 0.008741797879338264\n",
            "Epoch 86, Loss: 0.008492490276694298\n",
            "Epoch 87, Loss: 0.00825678464025259\n",
            "Epoch 88, Loss: 0.008033588528633118\n",
            "Epoch 89, Loss: 0.007821948267519474\n",
            "Epoch 90, Loss: 0.007621011231094599\n",
            "Epoch 91, Loss: 0.007429948542267084\n",
            "Epoch 92, Loss: 0.007248038426041603\n",
            "Epoch 93, Loss: 0.007074611261487007\n",
            "Epoch 94, Loss: 0.006909073330461979\n",
            "Epoch 95, Loss: 0.006750904023647308\n",
            "Epoch 96, Loss: 0.00659955432638526\n",
            "Epoch 97, Loss: 0.0064545804634690285\n",
            "Epoch 98, Loss: 0.006315593142062426\n",
            "Epoch 99, Loss: 0.006182209588587284\n",
            "Epoch 100, Loss: 0.006054028403013945\n",
            "Предсказанные оценки для пользователя 0: [ 2.585001   2.6611502 -2.557996  -2.6383967]\n",
            "Нормализованные оценки для пользователя 0: [4.928155  5.        0.0758562 0.       ]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Пример данных: матрица взаимодействий пользователей и объектов\n",
        "# 1 - пользователь взаимодействовал с объектом, 0 - нет\n",
        "interactions = np.array([\n",
        "    [1, 1, 0, 0],  # Пользователь 0\n",
        "    [1, 0, 0, 1],  # Пользователь 1\n",
        "    [0, 1, 1, 0],  # Пользователь 2\n",
        "    [0, 0, 1, 1],  # Пользователь 3\n",
        "], dtype=np.float32)\n",
        "\n",
        "# Гиперпараметры\n",
        "n_users, n_items = interactions.shape\n",
        "latent_dim = 10  # Количество латентных факторов\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "\n",
        "# Модель BPR\n",
        "class BPR(nn.Module):\n",
        "    def __init__(self, n_users, n_items, latent_dim):\n",
        "        super(BPR, self).__init__()\n",
        "        self.user_factors = nn.Embedding(n_users, latent_dim)\n",
        "        self.item_factors = nn.Embedding(n_items, latent_dim)\n",
        "        # Инициализация весов\n",
        "        nn.init.normal_(self.user_factors.weight, mean=0, std=0.01)\n",
        "        nn.init.normal_(self.item_factors.weight, mean=0, std=0.01)\n",
        "\n",
        "    def forward(self, u, i, j):\n",
        "        # Получаем латентные факторы для пользователей и объектов\n",
        "        u_factors = self.user_factors(u)\n",
        "        i_factors = self.item_factors(i)\n",
        "        j_factors = self.item_factors(j)\n",
        "        # Вычисляем предсказания\n",
        "        x_ui = torch.sum(u_factors * i_factors, dim=1)\n",
        "        x_uj = torch.sum(u_factors * j_factors, dim=1)\n",
        "        return x_ui - x_uj\n",
        "\n",
        "# Функция потерь BPR\n",
        "def bpr_loss(pred):\n",
        "    return -torch.log(torch.sigmoid(pred)).mean()\n",
        "\n",
        "# Подготовка данных\n",
        "def generate_triples(interactions):\n",
        "    triples = []\n",
        "    for u in range(n_users):\n",
        "        pos_items = np.where(interactions[u] == 1)[0]\n",
        "        neg_items = np.where(interactions[u] == 0)[0]\n",
        "        for i in pos_items:\n",
        "            for j in neg_items:\n",
        "                triples.append((u, i, j))\n",
        "    return np.array(triples)\n",
        "\n",
        "# Генерация троек (u, i, j)\n",
        "triples = generate_triples(interactions)\n",
        "\n",
        "# Преобразуем данные в тензоры\n",
        "triples = torch.tensor(triples, dtype=torch.long)\n",
        "\n",
        "# Модель и оптимизатор\n",
        "model = BPR(n_users, n_items, latent_dim)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Обучение модели\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    # Перемешиваем тройки\n",
        "    idx = torch.randperm(len(triples))\n",
        "    for batch in torch.split(triples[idx], 64):  # Мини-батчи\n",
        "        u, i, j = batch[:, 0], batch[:, 1], batch[:, 2]\n",
        "        pred = model(u, i, j)\n",
        "        loss = bpr_loss(pred)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "# Предсказание оценок\n",
        "def predict_ratings(model, user_id):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        u = torch.tensor([user_id], dtype=torch.long)\n",
        "        i = torch.arange(n_items, dtype=torch.long)\n",
        "        scores = torch.sum(model.user_factors(u) * model.item_factors(i), dim=1)\n",
        "    return scores.numpy()\n",
        "\n",
        "# Нормализация оценок\n",
        "def normalize_scores(scores, min_val=0, max_val=5):\n",
        "    scores_min = scores.min()\n",
        "    scores_max = scores.max()\n",
        "    return min_val + (scores - scores_min) * (max_val - min_val) / (scores_max - scores_min)\n",
        "\n",
        "# Пример предсказания для пользователя 0\n",
        "user_id = 0\n",
        "predicted_scores = predict_ratings(model, user_id)\n",
        "normalized_scores = normalize_scores(predicted_scores)\n",
        "print(f\"Предсказанные оценки для пользователя {user_id}: {predicted_scores}\")\n",
        "print(f\"Нормализованные оценки для пользователя {user_id}: {normalized_scores}\")"
      ]
    }
  ]
}